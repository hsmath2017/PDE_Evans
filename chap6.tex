\chapter{Elliptic equation}
In this chapter, we will discuss on the general elliptic PDEs and its weak form. We will exploit two essentially distinct techniques, energy methods within Sobolev spaces and maximum principle methods.
\section{Definition}
\subsection{Elliptic equations}
We will in this chapter mostly study the boundary value problem(BVP):
\begin{equation}
    \label{eq:Elliptic_eq}
    \left\{
        \begin{aligned}
            Lu&=f\text{ in }U;\\
            u&=0\text{ on }\partial U,\\
        \end{aligned}
    \right.
\end{equation} 
where $U$ is an open, bounded subset of $\mathbb{R}^{n}$, and $u:\bar{U}\rightarrow\mathbb{R}$ is the unknown. Here $f$ is given, and $L$ denotes a second order differential operator have either the form:
\begin{equation}
    \label{eq:div-form_ellip}
    Lu=-\sum_{i,j=1}^{n}\left(a^{ij}(x)u_{x_{i}}\right)_{x_{j}}+\sum_{i=1}^{n}b^{i}(x)u_{x_{i}}+c(x)u
\end{equation}
or else 
\begin{equation}
    \label{eq:non_div-form_ellip}
    Lu=-\sum_{i,j=1}^{n}a^{ij}(x)u_{x_{i}x_{j}}+\sum_{i=1}^{n}b^{i}(x)u_{x_{i}}+c(x)u.
\end{equation}
The form \eqref{eq:div-form_ellip} is in \textbf{divergence form}, while the form \eqref{eq:non_div-form_ellip} is in \textbf{non-divergence form}. The requirement that $u=0$ on $\partial\Omega$ is called \textbf{Dirichlet's boundary condition}.

\begin{remark}
    \begin{itemize}
        \item Different with Evans chapter 2, $u\in C^{2}(U)$ is unnecessary. So we should discuss on the weak form of equation \eqref{eq:Elliptic_eq}.
        \item If $a^{ij}\in C^{2}(U)$, the form \eqref{eq:div-form_ellip} and \eqref{eq:non_div-form_ellip} are equivalent in general. But the form \eqref{eq:div-form_ellip} is more natural for energy methods, and the form \eqref{eq:non_div-form_ellip} is more appropriate for maximum principle techniques.
        \item Assumption: \textbf{symmetry condition}
        \begin{equation*}
            \label{eq:symmetry_cond}
            a^{ij}=a^{ji}.
        \end{equation*}
    \end{itemize}
\end{remark}
Now, give an important property of the differential operator $L$.
\begin{definition}
    \label{defn:uniformly_elliptic}
    We say the partial differential operator $L$ is (uniformly) elliptic if there exists a constant $\theta>0$ such that
    \begin{equation}
        \sum_{i,j=1}^{n}a^{ij}(x)\xi_{i}\xi_{j}\ge\theta |\xi|^{2}
    \end{equation}
    for a.e. $x\in U$ and all $\xi\in\mathbb{R}^{n}$.
\end{definition}

\begin{remark}
    \begin{itemize}
        \item $L$ is uniformly elliptic means the matrix $(a^{ij}(x))$ is positive definite for a.e. $x\in U$.
        \item The converse proposition of the above proposition isn't true.
        \item Special case: $a^{ij}(x)\equiv\delta_{ij}, b^{i}\equiv 0, c^{i}\equiv 0$. In this case, the equation \eqref{eq:Elliptic_eq} is the \textbf{Poisson equation}.
    \end{itemize}
\end{remark}
\subsection{Weak solutions}
\textbf{Motivation:}In general case, we can only assume that 
\begin{equation}
    \label{eq:assumption_for_ellip}
    a^{ij},b^{i},c\in L^{\infty}(U),f\in L^{2}(U).
\end{equation} 
In this case, maybe we can't find $u\in C^{2}(U)$ such that $u$ satisfies \eqref{eq:Elliptic_eq}, so we try to derive the \textbf{weak form} of the solution $u$, such that $u\in H_{0}^{1}(U)$. In practise, choose \textbf{test function} $v\in C_{c}^{\infty}(U)$, then define the linear functional 
\begin{equation}
    \label{eq:functional_of_u}
    u^{*}(v):=\int_{U}uv\dif x.
\end{equation}
Then consider the dual form of \eqref{eq:Elliptic_eq}, i.e. 
\begin{equation}
    \label{eq:dual_form}
    (Lu)^{*}(v)=f^{*}(v)\text{ }\forall v\in C_{c}^{\infty}(U).
\end{equation}
It's just the \textbf{weak form} of equation \eqref{eq:Elliptic_eq}. In this section, we choose the \textbf{divergence form} of operator $L$.
\begin{theorem}
    The weak form of equation \eqref{eq:Elliptic_eq} is 
    \begin{equation}
        \label{eq:weak_form}
        \int_{U}\sum_{i,j=1}^{n}a^{ij}u_{x_{i}}v_{x_{j}}+\sum_{i=1}^{n}b^{i}u_{x_{i}}v+cuv\dif x=\int_{U}fv\dif x.
    \end{equation}
\end{theorem}
\begin{proof}
    It's suffices to derive the expression of $\int_{U}vLu\dif x$. By Gauss-Green formula, for a vector field $F\in C^{1}(\mathbb{R}^{n})$, we can see:
    \begin{equation}
        \label{eq:Gauss-Green}
        \int_{U}v\nabla\cdot F\dif x=\int_{\partial U}v F\cdot n\dif S(x)-\int_{U}F\cdot\nabla v\dif x.
    \end{equation}
    Choose the vector field $F=\begin{bmatrix}
        \sum a^{i1}(x)u_{x_{i}}\\
        \sum a^{i2}(x)u_{x_{i}}\\
        \vdots\\
        \sum a^{in}(x)u_{x_{i}}\\
    \end{bmatrix}$, as $v=0$ on $\partial \Omega$, by \eqref{eq:Gauss-Green}, we can see:
    \begin{equation}
        \begin{aligned}
            \int_{U}\sum_{i,j=1}^{n}\left(a^{ij}(x)u_{x_{i}}\right)_{x_{j}}v\dif x&=\int_{U}v\nabla\cdot F\dif x\\
            &=-\int_{U}F\cdot\nabla v\dif x\\
            &=-\int_{U}\sum_{i,j=1}^{n}a^{ij}u_{x_{i}}v_{x_{j}}\dif x.\\
        \end{aligned}
    \end{equation}
    Then:
    \begin{equation}
        \label{eq:weak}
        \int_{U}vLu\dif x=\int_{U}\sum_{i,j=1}^{n}a^{ij}u_{x_{i}}v_{x_{j}}+\sum_{i=1}^{n}b^{i}u_{x_{i}}v+cuv\dif x=\int_{U}vf\dif x=f^{*}(v).
    \end{equation}
\end{proof}
By \eqref{eq:weak_form}, we can derive the following definitions.
\begin{definition}
    \begin{enumerate}
        \item The bilinear form $B[\;,\;]$ associated with the divergence form elliptic operator defined by \eqref{eq:div-form_ellip} is:
        \begin{equation}
            \label{eq:bilinear_form_B1}
            B[u,v]:=\int_{U}\sum_{i,j=1}^{n}a^{ij}u_{x_{i}}v_{x_{j}}+\sum_{i=1}^{n}b^{i}u_{x_{i}}v
        \end{equation}
        for $u,v\in H_{0}^{1}(U)$.
        \item We say that $u\in H_{0}^{1}(U)$ is a weak solution of the BVP \eqref{eq:Elliptic_eq} if 
        \begin{equation}
            B[u,v]=(f,v)
        \end{equation}
        for all $v\in H_{0}^{1}(U)$, where $(\;,\;)$ denotes the inner product in $L^{2}(U)$.
    \end{enumerate}
\end{definition}

More generally, let us consider the BVP 
\begin{equation}
    \label{eq:revised_BVP}
    \left\{
        \begin{aligned}
            Lu&=f^{0}-\sum_{i=1}^{n}f_{x_{i}}^{i},x\in U,\\
            u&=0,x\in\partial U,
        \end{aligned}
    \right.
\end{equation}
where $f^{i}\in L^{2}(U)$. Then we say $u\in H_{0}^{1}(U)$ is a weak solution of problem \eqref{eq:revised_BVP} if 
\begin{equation}
    B[u,v]=\innerprod{f}{v}
\end{equation}
for all $v\in H_{0}^{1}(U)$, where $\innerprod{\cdot}{\cdot}$ is the pairing of $H^{-1}(U)$ and $H_{0}^{1}(U)$.

For non-homogeneous elliptic PDE, i.e.
\begin{equation}
    \label{eq:nonhomo}
    \left\{
        \begin{aligned}
            Lu&=f,x\in U,\\
            u&=g,x\in \partial U.\\
        \end{aligned}
    \right.
\end{equation}
By trace theorem, $\exists w\in H^{1}(U)$ such that the trace of $w$ is $g$. Then define $\tilde{u}:=u-w$, \eqref{eq:nonhomo} is equivalent to the equation:
\begin{equation}
    \label{eq:change_to_homogeneous}
    \left\{
        \begin{aligned}
            L\tilde{u}&=\tilde{f},x\in U,\\
            \tilde{u}&=0,x\in\partial U,\\
        \end{aligned}
    \right.
\end{equation}
where $\tilde{f}:=f-Lw\in H^{-1}(U)$.
\section{Existence of weak solutions}
\subsection{Lax-Milgram theorem}
We now introduce an abstract principle from linear functional analysis. 

Assume $H$ is a real Hilbert space, with norm $\|\;\|$ and inner product $(\;,\;)$. We let $\innerprod{\cdot}{\cdot}$ denote the pairing of $H$ with its dual space.
\begin{theorem}{Lax-Milgram Theorem}
    \label{thm:Lax-Milgram}
    Assume that 
    \begin{equation}
        \label{eq:bilinear_form_B}
        B:H\times H\rightarrow\mathbb{R}
    \end{equation}
    is a bilinear mapping, for which there exist constants $\alpha,\beta$ such that 
    \begin{equation}
        \label{eq:bounded}
        |B(u,v)|\le \alpha \norm{u}\norm{v}(u,v\in H)
    \end{equation}
    and 
    \begin{equation}
        \label{eq:elliptic}
        \beta\norm{u}^{2}\le B[u,u](u\in H).
    \end{equation}
    Finally, let $f:H\rightarrow R$ be a bounded linear functional on $H$.

    Then there exists a unique element $u\in H$ such that 
    \begin{equation}
        \label{eq:Lax-Milgram}
        B[u,v]=\innerprod{f}{v}
    \end{equation}
    for all $v\in H$.
\end{theorem}
\begin{remark}
    \begin{enumerate}
        \item If $B$ is symmetry, the condition \eqref{eq:bounded} and \eqref{eq:elliptic} means $B$ can derive an inner product on $H$.
        \item So, if $B$ is symmetry, theorem \ref{thm:Lax-Milgram} is a direct corollary of Riesz representation theorem.
        \item If $B$ isn't symmetry, Riesz representation theorem can transform $f\in H^{*}$ to $u_{f}\in H$, such that $\innerprod{f}{v}=(u_{f},v)$.
        \item So, we should show that $\forall u_{f}\in H$, $\exists u\in H$ such that $B[u,v]=(u_{f},v)$ for each $v\in H$.
    \end{enumerate}
\end{remark}
\begin{proof}

    By the remark above, we just need to show that $\forall u_{f}\in H$, $\exists u\in H$ such that $B[u,v]=(u_{f},v)$ for each $v\in H$.

    Consider an element $u\in H$. $B(u,v)$ is a bounded bilinear mapping, so the map 
    \begin{equation}
        \label{eq:Bu}
        B_{u}(v):=B[u,v]
    \end{equation}
    is a bounded linear functional. By Riesz representation theorem, $\exists !\tilde{u}\in H$ such that $B[u,v]=(\tilde{u},v)$ $\forall v\in H$. So we can define a map $A:H\rightarrow H$ maps $u$ to $\tilde{u}$.
    
    Then it's suffices to show that $A$ is a bounded linear isomorphism.

    First we should show that $A$ is linear. $\forall v\in H$, $\lambda_{1},\lambda_{2}\in\mathbb{R}$, $u_{1},u_{2}\in H$, we can see:
    \begin{equation}
        \label{eq:linear_A}
        \begin{aligned}
        (A(\lambda_{1}u_{1}+\lambda_{2}u_{2}),v)&=B[\lambda_{1}u_{1}+\lambda_{2}u_{2},v]\\
        &=\lambda_{1}B[u_{1},v]+\lambda_{2}B[u_{2},v]\\
        &=\lambda_{1}(Au_{1},v)+\lambda_{2}(Au_{2},v).
        \end{aligned}
    \end{equation}
    \eqref{eq:linear_A} shows that $A$ is a linear map. 

    Then we show that $A$ is bounded. As $B$ is bounded, we can see:
    \begin{equation}
        \label{eq:Bounded_A}
        \begin{aligned}
        \norm{Au}^{2}&=(Au,Au)\\
        &=B[u,Au]\\
        &\le \alpha \norm{u}\norm{Au}.
        \end{aligned}
    \end{equation}
    i.e. $\norm{Au}\le\alpha\norm{u}$. So $A$ is bounded.

    The next thing to do in the proof is to show $A$ is an injective. By \eqref{eq:elliptic}, we can see:
    \begin{equation}
        \label{eq:injective_A}
        \begin{aligned}
        \beta\norm{u}^{2}&\le B[u,u]\\
        &=(Au,u)\\
        &\le \norm{Au}\norm{u}.
        \end{aligned}
    \end{equation}
    i.e. $\beta\norm{u}\le\norm{Au}$. So $\beta\norm{u}\le \norm{Au}\le\alpha\norm{u}$, it means that $A$ is an injective. What's more, the range of $A$, marked as $R(A)$, is a closed set.
    
    Finally, we should show that $A$ is a surjective. If $R(A)\neq H$, since $R(A)$ is closed, there exists a nonzero element  $\omega\in H$ with $\omega\in R(A)^{\bot}$. Then: 
    \begin{equation}
        \beta\norm{\omega}^{2}\le B[\omega,\omega]=(A\omega,\omega)=0.
    \end{equation} 
    which means that $\norm{\omega}=0$, contradict! So $A$ is a surjective.

    This completes the proof of Lax-Milgram theorem.
\end{proof}

Lax-Milgram theorem gives an important method for us to analyze the existence of weak solution.
\subsection{Energy estimates and First Existence theorem}
Now, we return to the specific bilinear form $B[\;,\;]$ defined by \eqref{eq:bilinear_form_B1}, and try to use \textbf{Lax-Milgram theorem} to prove the first existence theorem.
\begin{theorem}{Energy estimates}
\label{thm:energy_estimate}
There exists constants $\alpha,\beta>0$ and $\gamma\ge 0$ such that 
\begin{equation}
    \label{eq:bounded_B}
    |B[u,v]|\le\alpha\norm{u}_{H_{0}^{1}(U)}\norm{v}_{H_{0}^{1}(U)}
\end{equation}
and 
\begin{equation}
    \label{eq:elliptic_B}
    \beta\norm{u}_{H_{0}^{1}(U)}^{2}\le B[u,u]+\gamma\norm{u}_{L^{2}(U)}^{2}.
\end{equation}
\end{theorem}
\begin{proof}
    First derive the inequality \eqref{eq:bounded_B}. According to \eqref{eq:bilinear_form_B1}, we can check that 
    \begin{equation}
        \label{eq:derive_energy_B}
        \begin{aligned}
            B[u,v]&\le\sum_{i,j=1}^{n}\int_{U}\norm{a^{ij}}_{L^{\infty}}|u_{x_{i}}||v_{x_{j}}|\dif x+\sum_{i=1}^{n}\int_{U}\norm{b^{i}}_{L^{\infty}}|u_{x_{i}}||v|\dif x+\int_{U}\norm{c}_{L^{\infty}}|u||v|\dif x\\
            &\le\sum_{i,j=1}^{n}\int_{U}\norm{a^{ij}}_{L^{\infty}}|Du||Dv|\dif x+\sum_{i=1}^{n}\int_{U}\norm{b^{i}}_{L^{\infty}}|Du||v|\dif x+\int_{U}\norm{c}_{L^{\infty}}|u||v|\dif x\\
            &\le\alpha\norm{u}_{H_{0}^{1}(U)}\norm{v}_{H_{0}^{1}(U)}.
        \end{aligned}
    \end{equation}
    Then, by the uniformly elliptic condition of coefficient matrix $a^{ij}(x)$, we can see:
    \begin{equation}
        \label{eq:elliptic_for_a}
        \begin{aligned}
        \theta\int_{U}|Du|^{2}\dif x&\le \int_{U}\sum_{i,j=1}^{n}a^{ij}(x)u_{x_{i}}u_{x_{j}}\dif x\\
        &=B[u,u]-\int_{U}\left(\sum_{i=1}^{n}b^{i}(x)u_{x_{i}}u\dif x+cu^{2}\right)\dif x\\
        &\le B[u,u]+\sum_{i=1}^{n}\int_{U}\norm{b^{i}(x)}_{\Linf}|u||Du|\dif x+c\int_{U}u^{2}\dif x\\ 
        \end{aligned}
    \end{equation}
    By Cauchy-Schwarz inequality with coefficient, we can see:
    \begin{equation}
        \label{eq:cauchy_schwarz}
        \int_{U}|u||Du|\dif x\le\epsilon\int_{U}|Du|^{2}\dif x+\frac{1}{4\epsilon}\int_{U}|u|^{2}\dif x.
    \end{equation}
    Choose $\epsilon$ such that $\epsilon\sum_{i=1}^{n}\norm{b^{i}}_{L^{\infty}}<\frac{\theta}{2}$, then exists constant $C>0$ such that 
    \begin{equation}
        \label{eq:inequality_for_ellip}
        \frac{\theta}{2}\int_{U}|Du|^{2}\dif x\le B[u,u]+C\int_{U}u^{2}\dif x.
    \end{equation}
    Finally, by Poincare-Friedrichs inequality, the equation \eqref{eq:elliptic_B} is true.
\end{proof}
By \eqref{eq:elliptic_B}, if $\gamma>0$, $B[u,v]$ isn't uniformly elliptic in general. So, $B[u,v]$ does't satisfy the hypotheses of Lax-Milgram theorem in general. So we should give some revisions on bilinear form $B$. Then, we derive the \textbf{first existence theorem for weak solutions.}
\begin{theorem}{First Existence Theorem for weak solutions}
    \label{thm:1st_exist}
    There is a number $\gamma\ge 0$ such that for each $\mu\ge\gamma$ and each function $f\in L^{2}(U)$, there exists a unique weak solution $u\in H_{0}^{1}(U)$ of the boundary-value problem 
    \begin{equation}
        \label{eq:modified_BVP}
        \left\{
            \begin{aligned}
                Lu+\mu u&=f,x\in U;\\
                u&=0,x\in\partial\Omega.\\
            \end{aligned}
        \right.
    \end{equation}
\end{theorem}
\begin{proof}
    Choose the parameter $\gamma$ as theorem \ref{thm:energy_estimate}, then define the bilinear form 
    \begin{equation}
        \label{eq:Bmu}
        B_{\mu}[u,v]:=B[u,v]+\mu(u,v).
    \end{equation}
    Then the weak form of equation \eqref{eq:modified_BVP} is 
    \begin{equation}
        B_{\mu}[u,v]=\innerprod{f}{v}.
    \end{equation}
    By \eqref{eq:elliptic_B}, as $\mu\ge\gamma$, the bilinear form $B_{\mu}$ satisfies uniformly elliptic condition. So by Lax-Milgram theorem, equation \eqref{eq:Bmu} has unique weak solution.
\end{proof}
\begin{remark}
    The first existence theorem for weak solutions is a milestone, but we still can't give the existence theorem of equation \eqref{eq:Elliptic_eq}. We should use Fredholm alternative theorem to derive the existence of weak solution.
\end{remark}
\subsection{Fredholm alternative and the solvability}
In this section, we show the Fredholm alternative theorem first, then employ this theorem to derive the existence theorem for weak solutions.

\begin{theorem}{Fredholm alternative}
    \label{thm:Fredholm}
    Let $K:H\rightarrow H$ be a compact linear operator, then:
    \begin{itemize}
        \item $\ker(I-K)$ is finite dimensional.
        \item $R(I-K)$ is closed.
        \item $R(I-K)=\ker(I-K^{*})^{\perp}$.
        \item $\ker(I-K)=\{0\}$ if and only if $R(I-K)=H$.
        \item $\dim\ker(I-K)=\dim\ker(I-K^{*})$.
    \end{itemize}
\end{theorem}
\begin{proof}
    Omitted.
\end{proof}
Then, derive the \textbf{dual problem} of equation \eqref{eq:Elliptic_eq}.
\begin{definition}{Dual problem}
    \begin{enumerate}
        \item The operator $L^{*}$, the formal adjoint of $L$, is:
        \begin{equation}
            \label{eq:dual_op}
            L^{*}v=-\sum_{i,j=1}^{n}\left(a^{ij}v_{x_{j}}\right)_{x_{i}}-\sum_{i=1}^{n}b^{i}v_{x_{i}}+(c-\sum_{i=1}^{n}b_{x_{i}}^{i})v,
        \end{equation}
        provided $b^{i}\in C^{1}(\bar{U})$.
        \item The adjoint bilinear form 
        \begin{equation}
            \label{eq:dualB}
            B^{*}:H_{0}^{1}(U)\times H_{0}^{1}(U)\rightarrow\mathbb{R}
        \end{equation}
        is defined by 
        \begin{equation}
            \label{eq:dual_B}
            B^{*}[v,u]=B[u,v]
        \end{equation}
        for all $u,v\in H_{0}^{1}(U)$.
        \item We say that $v\in H_{0}^{1}(U)$ is a weak solution of the adjoint problem 
        \begin{equation}
            \label{eq:adj_problem}
            \left\{
                \begin{aligned}
                    L^{*}v&=f,x\in U;\\
                    v&=0,x\in\partial U.
                \end{aligned}
            \right.
        \end{equation}
        provided $B^{*}[v,u]=(f,u)$ for all $u\in H_{0}^{1}(U)$.
    \end{enumerate}
\end{definition}
\begin{remark}
    \begin{itemize}
        \item \eqref{eq:dual_op} is called formal adjoint, for $(Lu,v)=(u,L^{*}v)$.
        \item \eqref{eq:adj_problem} is the dual form of equation \eqref{eq:Elliptic_eq}.
    \end{itemize}
\end{remark}
To show the solvability of problem \eqref{eq:Elliptic_eq}, we derive the following theorem.
\begin{theorem}{Second Existence Theorem for weak solutions}
    \label{thm:2nd_exist}
    \begin{enumerate}
        \item Precisely one of the following statements holds: either for each $f\in L^{2}(U)$ there exists a unique weak solution $u$ of the boundary value problem \eqref{eq:Elliptic_eq} (marked as $\alpha$), or else there exists a weak solution $u\neq 0$ of the homogeneous problem (marked as $\beta$) 
        \begin{equation}
            \label{eq:homo_prob}
            \left\{
                \begin{aligned}
                    Lu&=0,x\in U;\\
                    u&=0,x\in \partial U.
                \end{aligned}
            \right.
        \end{equation}
        \item Furthermore, should assertion $(\beta)$ hold, the dimension of the subspace $N\subset H_{0}^{1}(U)$ of weak solutions of \eqref{eq:homo_prob} is finite and equals the dimension of the subspace $N^{*}\subset H_{0}^{1}(U)$ of weak solutions of 
        \begin{equation}
            \label{eq:homo_dual}
            \left\{
                \begin{aligned}
                    L^{*}v&=0,x\in U;\\
                    v&=0,x\in\partial U.\\
                \end{aligned}
            \right.
        \end{equation}
        \item Finally, the BVP \eqref{eq:Elliptic_eq} has a weak solution if and only if 
        \begin{equation}
            (f,v)=0\;\forall v\in N^{*}.
        \end{equation}
    \end{enumerate}
\end{theorem}
\begin{remark}
    To prove this theorem, we should try to use theorem \ref{thm:1st_exist}. The main idea is to construct a compact operator $K$, such that the weak form of \eqref{eq:Elliptic_eq} is $(I-K)u=h$, then use theorem \ref{thm:Fredholm}.
\end{remark}
\begin{proof}
    First, choose $\gamma$ as theorem \ref{thm:1st_exist} suggests, then for each $g\in L^{2}(U)$, there exists a unique $u\in H_{0}^{1}(U)$ solving:
    \begin{equation}
        \label{eq:auxiliary_weak_form}
        B_{\gamma}[u,v]=\innerprod{g}{v}\forall v\in H_{0}^{1}(U).
    \end{equation}
    Write $u=L_{\gamma}^{-1}g$ if equation \eqref{eq:auxiliary_weak_form} holds. As the weak form of \eqref{eq:Elliptic_eq} is $B[u,v]=\innerprod{f}{v}$, we can see $B_{\gamma}[u,v]=\innerprod{f+\gamma u}{v}$, i.e. $u=L_{\gamma}^{-1}(f+\gamma u)$. Then choose operator $K=\gamma L_{\gamma}^{-1}$, $h=L_{\gamma}^{-1}f$, \eqref{eq:auxiliary_weak_form} is equivalent to 
    \begin{equation}
        \label{eq:compact_weak_form}
        (I-K)u=h.
    \end{equation}

    The next step is to show that $K:L^{2}(U)\rightarrow L^{2}(U)$ is a bounded, linear, compact operator. In fact, we only need to show $K$ is compact. By \eqref{eq:auxiliary_weak_form}, we can see:
    \begin{equation}
        \label{eq:norm_estimate}
        \beta\norm{u}_{H_{0}^{1}(U)}^{2}\le B_{\gamma}[u,u]=\innerprod{g}{u}\le\norm{g}_{L^{2}(U)}\norm{u}_{L^{2}(U)}\le\norm{g}_{L^{2}(U)}\norm{u}_{H_{0}^{1}(U)}.
    \end{equation}
    By \eqref{eq:norm_estimate}, there exists a constant $C>0$ such that $\norm{Kg}_{H_{0}^{1}(U)}\le C\norm{g}_{L^{2}(U)}$. As $H_{0}^{1}(U)\subset\subset L^{2}(U)$, $K$ is a compact operator.

    Then, use theorem \ref{thm:Fredholm} on equation \eqref{eq:compact_weak_form}. If $\ker(I-K)=\{0\}$, theorem \ref{thm:Fredholm} shows that $I-K$ is also a surjective, i.e. statement $(\alpha)$ is true. Otherwise, $\ker(I-K)\neq\{0\}$ means that $\exists u\in H_{0}^{1}(U)$ such that $(I-K)u=0$, i.e. $u$ satisfies equation \eqref{eq:homo_prob}. Then statement $(\beta)$ is true. If $N\neq\{0\}$, while
    \begin{equation}\dim\ker(I-K)=\dim\ker(I-K^{*})<\infty,
    \end{equation} we can see $\dim N=\dim N^{*}<\infty$.

    Finally, if $(I-K)u=h$ has a solution, $v\in N^{*}$, we can see:
    \begin{equation}
        \innerprod{h}{v}=\innerprod{(I-K)u}{v}=\innerprod{u}{(I-K^{*})v}=0.
    \end{equation}
    By $h=L_{\gamma}^{-1}f$, we can see:
    \begin{equation}
        \innerprod{h}{v}=\frac{1}{\gamma}\innerprod{Kf}{v}=\frac{1}{\gamma}\innerprod{f}{K^{*}v}=\frac{1}{\gamma}\innerprod{f}{v}=0.
    \end{equation}
    So:$\innerprod{f}{v}=0$.
\end{proof}
\subsection{Spectrum and third existence theorem}
In this section, we will discuss on the \textbf{spectrum} of an operator $L$, then derive the existence of weak solutions for eigenvalue problem.
\begin{theorem}{Third existence theorem for weak solutions}
    \begin{enumerate}
        \item There exists an at most countable set $\Sigma\subset\mathbb{R}$ such that the BVP 
        \begin{equation}
            \label{eq:eigen-BVP}
            \left\{
                \begin{aligned}
                    Lu&=\lambda u+f,x\in U;\\
                    u&=0,x\in\partial U\\
                \end{aligned}
            \right.
        \end{equation}
        has a unique weak solution for each $f\in L^{2}(U)$ if and only if $\lambda\notin\Sigma$.
        \item If $\Sigma$ is infinite, then $\Sigma=\{\lambda_{k}\}_{k=1}^{\infty}$, the values of a nondecreasing sequence with $\lambda_{k}\rightarrow+\infty$.
    \end{enumerate}
\end{theorem}
\begin{remark}
    \begin{enumerate}
        \item $\Sigma$ is called the \textbf{spectrum} of operator $L$.
        \item If $f=0$, the BVP \eqref{eq:eigen-BVP} is called eigenvalue problem, and if there exists a solution $\omega\neq 0$, $\lambda$ is called an \textbf{eigenvalue} of $L$, and $\omega$ is a corresponding \textbf{eigenfunction}. 
    \end{enumerate}
\end{remark}
\begin{proof}
    By theorem \ref{thm:2nd_exist}, if $\lambda\in\Sigma$, the homogeneous eigenvalue problem 
    \begin{equation}
        \label{eq:homo-eig-prob}
        \left\{
            \begin{aligned}
            Lu&=\lambda u,x\in U,\\
            u&=0,x\in\partial U
            \end{aligned}
        \right.
    \end{equation}
    has a solution $u\neq 0$. Consider it's weak form, we can see:
    \begin{equation}
        \label{eq:weak_form_for_eig_BVP}
        B_{\gamma}[u,v]=(\lambda+\gamma)\innerprod{u}{v}.
    \end{equation}
    i.e.
    \begin{equation}
        u=L_{\gamma}^{-1}(\gamma+\lambda)u=\frac{\lambda+\gamma}{\gamma}Ku.
    \end{equation}
    As $u\neq 0$, $u$ is the eigenvector of operator $K$, the corresponding eigenvalue is $\frac{\gamma}{\lambda+\gamma}$. By theorem \ref{thm:2nd_exist}, $K$ is a compact operator, so the Spectrum set $S$ of operator $K$ is either finite set, or else the values of a sequence converging to zero. It means that $\Sigma$ is at most countable, and if $|\Sigma|=\infty$, $\lambda_{k}\rightarrow\infty$.
\end{proof}

Finally, we note the boundedness of eigenvalue problem.
\begin{theorem}{Boundedness of the inverse}
If $\lambda\notin\Sigma$, there exists a constant $C$ such that 
\begin{equation}
    \label{eq:bounded}
    \norm{u}_{L^{2}(U)}\le C\norm{f}_{L^{2}(U)}
\end{equation}
whenever $f\in L^{2}(U)$ and $u$ is the unique weak solution of \eqref{eq:eigen-BVP}. The constant $C$ depends only on $\lambda,U$ and the coefficients of $L$.
\end{theorem}
\begin{proof}
    If not, there would exist sequences $\{f_{k}\}\subset L^{2}(U)$ and $\{u_{k}\}\subset H_{0}^{1}(U)$ such that 
    \begin{equation}
        \label{eq:counter}
        \left\{
            \begin{aligned}
        Lu_{k}&=\lambda u_{k}+f_{k},x\in U,\\
        u_{k}&=0,x\in \partial U,\\
            \end{aligned}
        \right.
    \end{equation}
    but 
    \begin{equation}
        \norm{u_{k}}_{L^{2}(U)}>k\norm{f_{k}}_{L^2(U)}.
    \end{equation}
    Assume WLOG, $\norm{u_{k}}_{L^2(U)}=1$, we can see $\norm{f_{k}}\rightarrow 0$. Then there exists a subsequence $\{u_{k_{j}}\}$ satisfies:
    \begin{equation}
        \label{eq:convergence}
        \left\{
            \begin{aligned}
                u_{k_{j}}&\rightharpoonup u\text{ in }H_{0}^{1}(U),\\
                u_{k_{j}}&\rightarrow u\text{ in }L^{2}(U).\\
            \end{aligned}
        \right.
    \end{equation}
    Then $u$ is a weak solution of \eqref{eq:homo-eig-prob}. Since $\lambda\notin\Sigma$, $u\equiv 0$. But $\norm{u_{k}}_{L^{2}(U)}\equiv 1$, contradict!
\end{proof}
\section{Interior Regularity}
Now, we try to discuss on the \textbf{regularity} of weak solutions. Consider a general PDE $Lu=f$, we find the weak solution $u\in H^{1}(U)$. However, if we set $f\in H^{m}(U)$, we expect $u\in H^{m+2}(U)$, it means we derive stronger regularity about the weak solution of $Lu=f$. The point of regularity is to derive analytic estimates from the structural, algebraic assumption of ellipticity.

First, recall the definition of difference quotients, and some related properties.
\begin{definition}{Difference quotient}
    \label{def:diff_quo}
    The $i$-th difference quotient of size $h$ is 
    \begin{equation}
        \label{eq:diff_quo}
        D_{i}^{h}u(x)=\frac{u(x+he_{i})-u(x)}{h}(i=1,\cdots,n)
    \end{equation}
    for $x\in V$ and $h\in\mathbb{R}$, $0<|h|<\text{dist}(V,\partial U)$. And $D^{h}(u):=\left(D_{1}^{h}u,\cdots,D_{n}^{h}u\right)$.
\end{definition}
The concept of difference quotients is related to weak derivatives, as the following theorem:
\begin{theorem}
    \label{thm:diff_and_dir}
    \begin{enumerate}
        \item Suppose $1\le p<\infty$ and $u\in W^{1,p}(U)$, for each $V\subset\subset U$, 
        \begin{equation}
            \norm{D^{h}u}_{L^{p}(V)}\le C\norm{Du}_{L^{p}(U)}
        \end{equation}
        for some constant $C$ and all $0<|h|<\frac{1}{2}\text{dist}(V,\partial U).$
        \item Assume $1<p<\infty$, $u\in L^{p}(V)$, and there exists a constant $C$ such that 
        \begin{equation}
            \norm{D^{h}u}_{L^{p}(V)}\le C
        \end{equation}
        for all $0<|h|<\frac{1}{2}\text{dist}(V,\partial U)$, then $u\in W^{1,p}(V)$ with $\norm{Du}_{L^{p}(V)}\le C$.        
    \end{enumerate}
\end{theorem}
\begin{proof}
    see \cite{evans2022partial} section 5.8, theorem 3.
\end{proof}

Then, introduce two lemmas for the integrate of difference quotients.
\begin{lemma}
    \label{lem:diff_quo}
    For a bounded open set $U$, and open set $W\subset\subset U$, 
    assume $v,w\in H^{1}(U)$,  $\text{supp}(w)\subset W$, $h<\frac{1}{2}\text{dist}(W,\partial U)$, then we can see:
    \begin{equation}
        \label{eq:int_by_part}
        \int_{U}vD_{k}^{-h}w\dif x=-\int_{U}wD_{k}^{h}v\dif x,
    \end{equation}
    and  
    \begin{equation}
        \label{eq:leibniz_for_diff}
        D_{k}^{h}(vw)=v^{h}D_{k}^{h}w+wD_{k}^{h}v,
    \end{equation}
    for $v^{h}(x):=v(x+he_{k})$.
\end{lemma}
\begin{proof}
    For equation \eqref{eq:int_by_part}, as $\text{supp} w\subset W$, we can see:
    \begin{equation}
        \begin{aligned}
        RHS&=-\int_{W}w(x)\frac{v(x+he_{k})-v(x)}{h}\dif x\\
        &=\frac{1}{h}\int_{W}w(x)v(x)\dif x-\frac{1}{h}\int_{W}w(x)v(x+he_{k})\dif x.
        \end{aligned}
    \end{equation}
    set $\tilde{W}:=\{y:y=x+he_{k},x\in W\}$, we can see:
    \begin{equation}
        \begin{aligned}
            LHS&=\frac{1}{h}\int_{U}v(x)\left(w(x)-w(x+he_{k})\right)\dif x\\
            &=\frac{1}{h}\int_{W}v(x)w(x)\dif x-\frac{1}{h}\int_{\tilde{W}}v(x)w(x-he_{k})\dif x.
        \end{aligned}
    \end{equation}
    By integral substitution, choose $y:=x-he_{k}$, we can see:
    \begin{equation}
        \int_{\tilde{W}}v(x)w(x-he_{k})\dif x=\int_{W}v(y+he_{k})w(y)\dif y.
    \end{equation}
    So, equation \eqref{eq:int_by_part} is true. Then, for equation \eqref{eq:leibniz_for_diff}, we can see:
    \begin{equation}
        \begin{aligned}
            LHS&=\frac{v(x+he_{k})w(x+he_{k})-v(x)w(x)}{h}\\
            &=\frac{v(x+he_{k})(w(x+he_{k})-w(x))+w(x)(v(x+he_{k})-v(x))}{h}\\
            &=v^{h}D_{k}^{h}w+wD_{k}^{h}v=RHS.
        \end{aligned}
    \end{equation}
\end{proof}
Then, we give the main result for this section:
\begin{theorem}{Interior $H^{2}$-regularity}
    \label{thm:interior_regularity}
    Assume $a^{ij}\in C^{1}(U)$, $b^{i},c\in L^{\infty}(U)$, and $f\in L^{2}(U)$. Suppose furthermore that $u\in H^{1}(U)$ is a weak solution of the elliptic PDE $Lu=f$, then:
    \begin{equation}
        u\in H_{loc}^{2}(U);
    \end{equation}
    and for each open subset $V\subset\subset U$ we have the estimate 
    \begin{equation}
        \label{eq:estimate_H2_u}
        \norm{u}_{H^{2}(V)}\le C\left(\norm{f}_{L^{2}(U)}+\norm{u}_{L^{2}(U)}\right),
    \end{equation}
    the constant $C$ depending only on $V$, $U$, and the coefficients of operator $L
    $.
\end{theorem}
Before the proof of this theorem, we should give some remarks.

\begin{remark}
    \begin{enumerate}
        \item In this theorem, we don't require $u\in H_{0}^{1}(U)$.
        \item Since $u\in H_{loc}^{2}(U)$, we have
        \begin{equation}
            Lu=f\text{ a.e. in U}.
        \end{equation}
    \end{enumerate}
\end{remark}

\textbf{The idea} : First, construct a truncated function $\zeta\in C^{\infty}(U)$ such that $V\subset\subset W\subset\subset U$, $\zeta|_{V}\equiv 1$, $\zeta|_{U\setminus W}\equiv 0$. Then, choose a test function 
\begin{equation}
    \label{eq:test_func}
    v(x)=-D_{k}^{-h}\left(\zeta^{2}D_{k}^{h}u(x)\right)\in H_{0}^{1}(U).
\end{equation}
In fact, if $u\in C^{2}(U)$, $v$ is a difference quotient approximation for $D^{2}u$. Finally, use the relation $B[u,v]=(f,v)$ to approximate $\norm{D_{k}^{h}Du}_{L^{2}(V)}$, and use the second part of theorem \ref{thm:diff_and_dir}.
\begin{proof}
    By the definition of weak solution, $B[u,v]=(f,v)$. Then we can see:
    \begin{equation}
        \label{eq:modified_weak_sol}
        \sum \int_{U}a^{ij}u_{x_{i}}v_{x_{j}}\dif x=\int_{U}(f-\sum b_{i}u_{x_{i}}-cu)v\dif x.
    \end{equation}
    mark 
    \begin{equation}
        \label{eq:expression_for_A}
        A=\sum\int_{U}a^{ij}u_{x_{i}}v_{x_{j}}\dif x,
    \end{equation}
    and choose $v$ as \eqref{eq:test_func}, according to lemma \ref{lem:diff_quo}, we can derive:
    \begin{equation}
        \label{eq:partition_for_A}
        \begin{aligned}
        A&=-\int_{U}\sum a^{ij}u_{x_{i}}\left(D_{k}^{-h}\left(\zeta^{2}D_{k}^{h}u(x)\right)\right)_{x_{j}}\dif x\\
        &=\sum\int_{U}D_{k}^{h}\left(a^{ij}u_{x_{i}}\right)\left(\zeta^{2}D_{k}^{h}u(x)\right)_{x_{j}}\dif x\\
        &=\sum\int_{U}\left(a^{ij,h}D_{k}^{h}u_{x_{i}}+u_{x_{i}}D_{k}^{h}(a^{ij})\right)\left(2\zeta\zeta_{x_{j}}D_{k}^{h}u(x)+\zeta^{2}\left(D_{k}^{h}u(x)\right)_{x_{j}}\right)\dif x\\
        &=\sum\int_{U}a^{ij,h}\zeta^{2}D_{k}^{h}u_{x_{i}}D_{k}^{h}u_{x_{j}}\dif x\\
        &+\sum\int_{U}\left(2\zeta\zeta_{x_{j}}u_{x_{i}}D_{k}^{h}(a^{ij})D_{k}^{h}u(x)+2\zeta\zeta_{x_{j}}a^{ij,h}D_{k}^{h}u_{x_{i}}D_{k}^{h}u(x)+\zeta^{2}u_{x_{i}}D_{k}^{h}(a^{ij})\left(D_{k}^{h}u(x)\right)_{x_{j}}\right)\dif x\\
        &:=A_{1}+A_{2}.
        \end{aligned}
    \end{equation}
    By the uniform elliptic property, there exists $\theta>0$ such that 
    \begin{equation}
        \label{eq:approx_A1}
        A_{1}\ge \theta\int_{U}\zeta^{2}|D_{k}^{h}Du|^{2}\dif x.
    \end{equation}
    Then we try to approx $|A_{2}|$. As $a^{ij}\in C^{1}(U)$, $\zeta\in C^{\infty}(U)$, we can see:
    \begin{equation}
        \label{eq:approx_A2}
        \begin{aligned}
            |A_{2}|&\le \sum\int_{U}\left(C_{1}\zeta|u_{x_{i}}||u(x)|+C_{2}\zeta|D_{k}^{h}u_{x_{i}}||D_{k}^{h}u(x)|+C_{3}\zeta|u_{x_{i}}|\left(D_{k}^{h}u(x)\right)_{x_{j}}\right)\dif x\\
            &\le C\int_{U}\left(\zeta|Du||u|+\zeta|D_{k}^{h}Du||D_{k}^{h}u|+\zeta|Du||D_{k}^{h}Du|\right)\dif x\\
            &\le \frac{\theta}{2} \int_{U}\zeta^{2}|D_{k}^{h}Du|^{2}\dif x+\tilde{C}\int_{U}|Du|^{2}+|D_{k}^{h}u|^{2}\dif x\\
            &\le\frac{\theta}{2}\int_{U}\zeta^{2}|D_{k}^{h}Du|^{2}\dif x+M\int_{U}|Du|^{2}\dif x.
        \end{aligned}
    \end{equation}
    In equation \eqref{eq:approx_A2}, $C_{1},C_{2},C_{3},C,\tilde{C},M$ are all constants. The first step follows from $a^{ij},\zeta\in C^{1}(U)$, the second and the third steps from Cauchy-Schwarz inequality, and the last from theorem \ref{thm:diff_and_dir}.

    Combining \eqref{eq:approx_A1} and \eqref{eq:approx_A2}, we can see 
    \begin{equation}
        \label{eq:approx_A}
        A\ge \frac{\theta}{2}\int_{U}\zeta^{2}|D_{k}^{h}Du|^{2}\dif x-M\int_{U}|Du|^{2}\dif x.
    \end{equation}

    The next step is to approximate the right-hand integral 
    \begin{equation}
        \label{eq:integral_B}
        B:=\int_{U}(f-\sum b_{i}u_{x_{i}}-cu)v\dif x.
    \end{equation}
    First, as $b_{i}\in C^{1}(U)$, we can see 
    \begin{equation}
        \label{eq:approx1_B}
        |B|\le C\int_{U}(|f|+|Du|+|u|)|v|\dif x.
    \end{equation}
    Then, consider 
    \begin{equation}
        \label{eq:approx_int_v2}
        \begin{aligned}
            \int_{U}v^{2}\dif x&=\int_{U}|D_{k}^{-h}(\zeta^{2}D_{k}^{h}u)|^{2}\dif x\\
            &\le C\int_{U}D|\zeta^{2}D_{k}^{h}u|^{2}\dif x\\
            &\le C\int_{U}\zeta^{2}|D_{k}^{h}Du|^{2}\dif x+C\int_{W}|D_{k}^{h}u|^{2}\dif x\\
            &\le C\int_{U}\left(|Du|^{2}+\zeta^{2}|D_{k}^{h}Du|^{2}\right)\dif x.
        \end{aligned}
    \end{equation}
    The second step follows from theorem \ref{thm:diff_and_dir}, the third step follows from the Leibniz formula, and the final step follows from theorem \ref{thm:diff_and_dir} as well.
    
    Finally, by \eqref{eq:approx1_B} , \eqref{eq:approx_int_v2} and Cauchy-Schwarz inequality, there exists constant $C$ such that 
    \begin{equation}
        \label{eq:approx_B}
        |B|\le\frac{\theta}{4}\int_{U}\zeta^{2}|D_{k}^{h}Du|^{2}\dif x+C\int_{U}\left(|f|^2+|u|^2+|Du|^2\right)\dif x.
    \end{equation}
    
    By the estimation \eqref{eq:approx_A} and \eqref{eq:approx_B}, it's clear that $\forall h>0$, $\exists$ constant $C>0$, such that 
    \begin{equation}
        \int_{V}|D_{k}^{h}Du|^{2}\dif x\le C(\norm{f}_{L^{2}(U)}+\norm{u}_{H^{1}(U)}).
    \end{equation}
    It means that $Du\in H^{1}(V)$, and 
    \begin{equation}
        \norm{u}_{H^{2}(V)}\le C\left(\norm{f}_{L^{2}(U)}+\norm{u}_{H^{1}(U)}\right).
    \end{equation}

    Finally, choose auxiliary function $\xi\in C^{\infty}(U)$, $\text{supp}\xi\subset U$ and $\xi\equiv 1$ on $W$, set $v=\xi^{2}u$, according to equation \eqref{eq:modified_weak_sol}, we can see:
    \begin{equation}
        \int_{U}\xi^{2}|Du|^{2}\dif x\le C\int_{U}(f^{2}+u^2)\dif x.
    \end{equation}
    Then:
    \begin{equation}
        \label{eq:estimate_u_H1}
        \norm{u}_{H^{1}(W)}\le C\left(\norm{f}_{L^{2}(U)}+\norm{u}_{L^{2}(U)}\right).
    \end{equation}
\end{proof}
\begin{remark}
    Theorem \ref{thm:interior_regularity} shows the condition for the higher regularity of weak solutions.
\end{remark}
Then, we introduce the higher interior regularity.
\begin{theorem}{Higher interior regularity}
    \label{thm:higher_int_regular}
    Let $m$ be a nonnegative integer, and assume $a^{ij},b^{i},c\in C^{m+1}(U)$, and $f\in H^{m}(U)$. Suppose $u\in H^{1}(U)$ is a weak solution of the elliptic PDE
    \begin{equation}
        Lu=f,
    \end{equation}
    then $u\in H_{loc}^{m+2}(U)$ and for each $V\subset\subset U$ we have the estimate 
    \begin{equation}
        \norm{u}_{H^{m+2}(V)}\le C(\norm{f}_{H^{m}(U)}+\norm{u}_{L^{2}(U)}).
    \end{equation}
\end{theorem}
\begin{proof}
    We prove this theorem by induction. If $m=0$, theorem \ref{thm:higher_int_regular} is equivalent to theorem \ref{thm:interior_regularity}, so the induction basis is true. Assume theorem \ref{thm:higher_int_regular} is true for $m=k$, i.e. if $a^{ij},b^{i},c\in C^{k+1}(U)$, $f\in H^{k}(U)$, the weak solution $u\in H^{1}(U)$ satisfies
    \begin{equation}
        \norm{u}_{H^{k+2}(W)}\le C(\norm{f}_{H^{k}(U)}+\norm{u}_{L^{2}(U)}).
    \end{equation}
    for each $W\subset\subset U$ and approximate constant $C$, and $u\in H_{loc}^{k+2}(U)$. Then let $\alpha$ be any multiindex with $|\alpha|=m+1$ and choose any auxiliary function $\tilde{v}\in C_{c}^{\infty}(W)$. Choose the test function $v=(-1)^{|\alpha|}D^{\alpha}\tilde{v}$, insert it into the weak form $B[u,v]=(f,v)$, perform some integrations by parts, we discover:
    \begin{equation}
        \label{eq:Buv_int_by_part}
        \begin{aligned}
            B[u,v]&=\sum\int_{U}a^{ij}u_{x_{i}}(-1)^{|\alpha|}(D^{\alpha}\tilde{v})_{x_{j}}\dif x+\sum\int_{U}b^{i}u_{x_{i}}(-1)^{|\alpha|}D^{\alpha}\tilde{v}\dif x+\int_{U}cu(-1)^{|\alpha|}D^{\alpha}\tilde{v}\dif x\\
            &=\sum\int_{U}D^{\alpha}(a^{ij}u_{x_{i}})\tilde{v}_{x_{j}}\dif x+\sum\int_{U}D^{\alpha}(b^{i}u_{x_{i}})\tilde{v}\dif x+\int_{U}D^{\alpha}(cu)\tilde{v}\dif x\\
            &=B[D^{\alpha}u,\tilde{v}]-\sum_{i,j}\sum_{\beta\le\alpha}\int_{U}\binom{\alpha}{\beta}(D^{\alpha-\beta}a^{ij}D^{\beta}u_{x_{i}})_{x_{j}}\tilde{v}\dif x+\sum_{i}\sum_{\beta\le\alpha}\int_{U}D^{\alpha-\beta}b^{i}D^{\beta}u_{x_{i}}\tilde{v}\dif x\\
            &+\sum_{\beta\le\alpha}\int_{U}D^{\alpha-\beta}cD^{\beta}u\tilde{v}\dif x.
        \end{aligned}
    \end{equation}
    So if we write $\tilde{u}:=D^{\alpha}u$, we can see:
    \begin{equation}
        B[\tilde{u},\tilde{v}]=(\tilde{f},\tilde{v}).
    \end{equation}
    Where 
    \begin{equation}
        \tilde{f}:=D^{\alpha}f-\sum_{\beta<\alpha}\binom{\alpha}{\beta}\left[-\sum(D^{\alpha-\beta}a^{ij}D^{\beta}u_{x_{i}})_{x_{j}}+\sum D^{\alpha-\beta}b^{i}D^{\beta}u_{x_{i}}+D^{\alpha-\beta}cD^{\beta}u\right].
    \end{equation}
    We can see that $\tilde{u}$ is the weak solution of equation $L\tilde{u}=\tilde{f}$. Since $a^{ij},b^{i},c\in C^{k+2}(U)$, $f\in H^{k+1}(U)$, we can see $\tilde{f}\in L^{2}(W)$, and 
    \begin{equation}
        \norm{\tilde{f}}_{L^{2}(W)}\le C\left(\norm{f}_{H^{m+1}(U)}+\norm{u}_{L^{2}(U)}\right).
    \end{equation}
    In light of theorem \ref{thm:interior_regularity}, we see $\tilde{u}\in H^{2}(V)$ with 
    \begin{equation}
        \norm{\tilde{u}}_{H^{2}(V)}\le\ C(\norm{f}_{H^{m+1}(U)}+\norm{u}_{L^{2}(U)}).
    \end{equation}
    As the inequality holds for all multiindex $\alpha$ satisfies $|\alpha|=m+1$, the proof is completed.
\end{proof}
\section{Boundary regularity}
Now, we extend to give the regularity of weak solution for homogeneous Dirichlet boundary value problem. In fact, when it comes to Dirichlet BVPs, the result comes to be stronger.
\begin{theorem}{Boundary $H^{2}$-regularity}
    \label{thm:boundary_regularity}
Assume $a^{ij}\in C^{1}(\bar{U}), b^{i},c\in L^{\infty}(U)$ and $f\in L^{2}(U)$. Suppose that $u\in H_{0}^{1}(U)$ is a weak solution of the elliptic BVP \eqref{eq:Elliptic_eq}. Assume finally $\partial U$ is $C^{2}$, then $u\in H^{2}(U)$ and we have the estimate
\begin{equation}
    \label{eq:estimate_for_Dirichlet}
    \norm{u}_{H^{2}(U)}\le C(\norm{f}_{L^{2}(U)}+\norm{u}_{L^{2}(U)}).
\end{equation}
The constant $C$ depending only on $U$ and the coefficients of $L$.
\end{theorem}
\begin{remark}
    \begin{itemize}
        \item Main difference from theorem \ref{thm:interior_regularity}: now $u\in H^{2}(U)$ rather than $u\in H_{loc}^{2}(U)$.
        \item If equation \eqref{eq:Elliptic_eq} has unique solution, we can see $\norm{u}_{H^{2}(U)}\le C\norm{f}_{L^{2}(U)}$ from theorem \ref{thm:boundary_regularity}. This result shows the \textbf{well-posed} of elliptic equation.
        \item In this theorem, we assume $u\equiv 0$ along $\partial U$ in the trace case.
    \end{itemize}
\end{remark}
\textbf{The idea of the proof}: First, consider the special case that $U$ is a half-ball, then $\forall x_{0}\in \partial U$, choose a homologeous map from $B(x_{0},\epsilon)\cap U$ to the half ball. Finally, use the compactness of $\partial U$.
\begin{proof}
    First, consider the case $U=B(0,1)\cap\mathbb{R}_{+}^{n}$. The target is to show that $\exists V\subset\subset U$ with $\partial V\cap\partial U\neq\emptyset$ such that 
    \begin{equation}
        \label{eq:estimate_ball}
        \norm{u}_{H^{2}(V)}\le C(\norm{f}_{L^{2}(U)}+\norm{u}_{L^{2}(U)}).
    \end{equation}
    To derive the $H^{2}$ norm on subset $V:=B(0,\frac{1}{2})\cap\mathbb{R}_{+}^{n}$, we first derive the truncated function $\zeta\in C^{\infty}(U)$ satisfies:
    \begin{equation}
        \label{eq:truncated_func}
        \left\{
            \begin{aligned}
                &\zeta\equiv 1,x\in B(0,\frac{1}{2})\\
                &\zeta\equiv 0,x\notin B(0,1),\\
                &0\le\zeta\le 1,\\
            \end{aligned}
        \right.
    \end{equation}
    such that $\zeta$ vanishes near the curved part of $\partial U$. Since $u$ is a weak solution of equation \eqref{eq:Elliptic_eq}, we have $B[u,v]=(f,v)$ for all $v\in H_{0}^{1}(V)$. Consequently, we can also write the auxiliary equation \eqref{eq:auxiliary_weak_form}. Then we should derive the form of $v\in H_{0}^{1}(U)$.

    Consider $1\le k\le n-1$, set $v=-D_{k}^{-h}(\zeta^{2}D_{k}^{h}u)$, first we claim that $v\in H_{0}^{1}(U)$. In fact:
    \begin{equation}
        \label{eq:expression_for_v}
        v(x)=\frac{1}{h^2}\left[\zeta^2(x-he^{k})u(x)+\zeta^2(x)u(x)-\zeta^2(x)u(x+he^{k})-\zeta^2(x-he^{k})u(x-he^{k})\right].
    \end{equation}
    On the face $\{x_{n}=0\}$, by the definition of weak solution, $u(x)=0$. And near the curved part of $\partial U$, by the definition of $\zeta$, $\zeta(x)=0$. So on $\partial U$, we can see $v(x)\equiv 0$, i.e. $v(x)\in H_{0}^{1}(U)$.

    Then, by equation \eqref{eq:auxiliary_weak_form} and the same method as theorem \ref{thm:interior_regularity}, we can see that for $1\le k\le n-1$, 
    \begin{equation}
        \int_{V}|D_{k}^{h}Du|^{2}\dif x\le C\left(\norm{f}_{L^{2}(U)}+\norm{u}_{H^{1}(U)}\right).
    \end{equation}
    i.e.
    \begin{equation}
        \label{eq:estimate_1_for_half_ball}
        \sum_{\substack{k+l<2n\\k=l=1}}^{n}\int_{V}|u_{x_{k}x_{l}}^{2}|\dif x\le C\left(\norm{f}_{L^{2}(U)}+\norm{u}_{H^{1}(U)}\right).
    \end{equation}
    But we can't estimate $\norm{u_{x_{n}x_{n}}}_{L^{2}(V)}$ by this method, for $x-he^{n}$ may lie outside the region $U$. Now we rewrite the equation \eqref{eq:Elliptic_eq} by nondivergence form, i.e.
    \begin{equation}
        -\sum_{i,j=1}^{n}a^{ij}u_{x_{i}x_{j}}+\sum_{i=1}^{n}\tilde{b}^{i}u_{x_{i}}+cu=f.
    \end{equation}
    As $a^{ij}(x)$ satisfies \textbf{uniformly elliptic condition}, there exists $\theta>0$ such that $a^{nn}(x)\ge \theta\;\forall x\in U$. So:
    \begin{equation}
        \label{eq:estimate_2_for_half_ball}
        |u_{x_{n}x_{n}}|\le C\left(\sum_{\substack{i,j=1\\i+j<2n}}^{n}|u_{x_{i}x_{j}}|+|Du|+|u|+|f|\right).
    \end{equation}
    By \eqref{eq:estimate_1_for_half_ball}, \eqref{eq:estimate_2_for_half_ball} and \eqref{eq:estimate_u_H1}, we conclude $u\in H^{2}(V)$ and 
    \begin{equation}
        \label{eq:estimate_on_half_ball}
        \norm{u}_{H^{2}(V)}\le C\left(\norm{f}_{L^{2}(U)}+\norm{u}_{L^{2}(U)}\right).
    \end{equation}

    Then, we drop the assumption that $U$ is a half-ball. In general case, we choose any point $x^{0}\in\partial U$ and note that since $\partial U$ is $C^{2}$, we may assume that 
    \begin{equation}
        U\cap B(x^{0},r)=\{x\in B(x^{0},r)|x_{n}>\gamma(x_{1},\cdots,x_{n-1})\}
    \end{equation}
    for some $r<0$ and some $C^{2}$ function $\gamma$. Consider the "flatten out" map as follows:
    \begin{equation}
        \Phi^{i}(x)=\left\{
            \begin{aligned}
                &x_{i},i=1,\cdots,n-1;\\
                &x_{n}-\gamma(x_{1},\cdots,x_{n-1}),i=n.\\
            \end{aligned}
        \right.
    \end{equation}
    Then write $y=\Phi(x)$, $x=\Psi(y)$ as the linear map from $U\cap B(x^{0},r)$ to $\tilde{U}$. We can see $\tilde{U}$ has a piece of boundary as $y_{n}=0$. Finally, we define $u'(y):=u(\Psi(y))$, it's clear that $u'\in H^{1}(\tilde{U})$ and $u'=0$ on $\partial \tilde{U}\cap \{y_{n}=0\}$. Now, we transform equation \eqref{eq:Elliptic_eq} to the equation related to $u'$ on $\tilde{U}$.

    Write the PDE related to $u'$ as 
    \begin{equation}
        \label{eq:modified_equation_for_u}
        L'u'=f',
    \end{equation}
    with the function $f'(y):=f(\Psi(y))$, and the operator 
    \begin{equation}
        L'u':=-\sum_{k,l=1}^{n}(a^{'kl}u'_{y_{k}})_{y_{l}}+\sum_{k=1}^{n}b^{'k}u'_{y_k}+c'u'.
    \end{equation}
    where 
    \begin{equation}
        \label{eq:aprime}
        a^{'kl}(y)=\sum_{r,s=1}^{n}a^{rs}(\Psi(y))\Phi_{x_{r}}^{k}(\Psi(y))\Phi_{x_{s}}^{l}(\Psi(y)),
    \end{equation}
    \begin{equation}
        \label{eq:bprime}
        b^{'k}(y)=\sum_{r=1}^{n}b^{r}(\Psi(y))\Phi_{x_{r}}^{k}(\Psi(y)),
    \end{equation}
    and 
    \begin{equation}
        \label{eq:cprime}
        c'(y)=c(\Psi(y)),
    \end{equation}
    for $y\in U'$, $k,l=1,\cdots,n$. In fact, the operator is derived using the chain rule of derivatives.

    If $v'\in H_{0}^{1}(U')$ and $B'[\cdot,\cdot]$ denotes the bilinear form associated with the operator $L'$, we have:
    \begin{equation}
        \label{eq:coordinate_change_B}
        B'[u',v']=\int_{\tilde{U}}\sum a^{'kl}u_{y_k}^{'}v_{y_l}^{'}+\sum b^{'k}u_{y_k}^{'}v'+c'u'v'\dif y. 
    \end{equation}
    Set the function $v'(x)=v(\Psi(x))$, and we define $u'(x)=u(\Psi(x))$ before, by \eqref{eq:coordinate_change_B}, we can see:
    \begin{equation}
        \label{eq:form_of_B}
        \begin{aligned}
            B'[u',v']&=\sum\int_{\tilde{U}}a^{'kl}u_{x_{i}}\Psi_{y_{k}}^{i}v_{x_{j}}\Psi_{y_{l}}^{j}\dif y+\sum\int_{\tilde{U}}b^{'k}u_{x_{i}}\Psi_{y_{k}}^{i}v\dif y+\int_{\tilde{U}}c'uv\dif y.
        \end{aligned}
    \end{equation}
    In the following equation, $u$, $v$ means $u(\Psi(y))$, $v(\Psi(y))$ respectively. By equation \eqref{eq:aprime}, we can see:
    \begin{equation}
        \sum_{k,l}a^{'kl}\Psi_{y_{k}}^{i}\Psi_{y_{l}}^{j}=\sum_{r,s}\sum_{k,l}a^{rs}\Phi_{x_{r}}^{k}\Phi_{x_{s}}^{l}\Psi_{y_{k}}^{i}\Psi_{y_{l}}^{j}=a^{ij}
    \end{equation}
    since $D\Psi=(D\Phi)^{-1}$. Similarly,
    \begin{equation}
        \sum_{k=1}^{n}b^{'k}\Psi_{y_{k}}^{i}=b^{i}.
    \end{equation}
    So:
    \begin{equation}
        \label{eq:samesol}
        B'[u',v']=B[u,v]=\innerprod{f}{v}=\innerprod{f'}{v'},
    \end{equation}
    i.e. the auxiliary PDE has the same solution as original PDE.

    Then we check the operator $L'$ is uniformly elliptic in $U'$. If $y\in U'$ and $\xi\in\mathbb{R}^{n}$, we note that 
    \begin{equation}
        \sum_{k,l=1}^{n}a^{'kl}(y)\xi_{k}\xi_{l}=\sum_{k,l}\sum_{r,s}a^{rs}(\Psi(y))\Phi_{x_{r}}^{k}\Phi_{x_{s}}^{l}\xi_{k}\xi_{l}=\sum_{r,s}a^{rs}(\Psi(y))\eta_{r}\eta_{s}\ge\theta|\eta|^{2}.
    \end{equation}
    where $\eta=\xi D\Phi$. So $L'$ is uniformly elliptic on $\tilde{U}$. It's clear that $a^{'ij},b^{'i},c'\in C^{1}(\tilde{U})$.

    Finally, by equation \eqref{eq:estimate_on_half_ball} and \eqref{eq:samesol}, we can see that 
    \begin{equation}
        \norm{u}_{H^{2}(V)}\le C\left(\norm{f}_{L^{2}(U)}+\norm{u}_{L^{2}(U)}\right)
    \end{equation}
    for an open neighborhood $V$ of $x^{0}$. 

    Since $\partial U$ is compact, we can cover $\partial U$ with finitely many sets $V_{1},\cdots, V_{N}$ as above. Sum them up, then complete the proof.
\end{proof}

Then, derive the higher boundary regularity
\begin{theorem}{Higher boundary regularity}
    Let $m$ be a nonnegative integer, and assume $a^{ij},b^{i},c\in C^{m+1}(\bar{U})$, and $f\in H^{m}(U)$, suppose that $u\in H_{0}^{1}(U)$ is a weak solution of the BVP
    \begin{equation}
        \left\{
            \begin{aligned}
                Lu&=f,x\in U;\\
                u&=0,x\in\partial U.
            \end{aligned}
        \right.
    \end{equation}
    Assume finally $\partial U\in C^2$, then $u\in H^{m+2}(U)$ and we have the estimate
    \begin{equation}
        \norm{u}_{H^{m+2}(U)}\le C(\norm{f}_{H^{m}(U)}+\norm{u}_{L^{2}(U)}).
    \end{equation}
\end{theorem}
\begin{proof}
    Skip. See \cite{evans2022partial} Page 343-345.
\end{proof}

In this section, the basic tool of integration by parts has eventually taken us from weak solution $u\in H_{0}^{1}(U)$ to smooth, classical solutions.
\section{Maximum Principles}
In this section, we concentrate on the properties of elliptic operator $L$, and we assume that $u\in C^{2}(U)$. As $u\in C^{2}(U)$, we can see if $u(x)$ attains its maximum over $U$, then $Du(x_{0})=0,D^{2}u(x_{0})\le 0$. Now, we consider elliptic operators $L$ having the nondivergence form:
\begin{equation}
    \label{eq:div_form}
    Lu=-\sum_{i,j=1}^{n}a^{ij}u_{x_{i}x_{j}}+\sum_{i=1}^{n}b^{i}u_{x_{i}}+cu,
\end{equation}
where the coefficients $a^{ij},b^{i},c$ are continuous and the uniform ellipticity condition \ref{defn:uniformly_elliptic} holds. Without loss of generality, we assume the symmetry condition $a^{ij}=a^{ji}$.
\subsection{Weak maximum principle}
First, assume $U\subset\mathbb{R}^{n}$ is open and bounded, we will show that if $Lu\le 0$ in $U$ and $c\equiv 0$, $u$ must attain its maximum on $\partial U$.
\begin{theorem}{Weak maximum principle}
    \label{thm:WMP}
    Assume $u\in C^{2}(U)\cap C^{1}(\bar{U})$ and $c\equiv 0$ in $U$, if $Lu\le 0$ in $U$, then
    \begin{equation}
        \label{eq:max_principle}
        \max_{\bar{U}}u=\max_{\partial U}u.
    \end{equation}
\end{theorem} 
\begin{proof}
    First, consider a stronger case, i.e. $Lu<0$. Assume there exists a point $x_{0}\in U$ such that $u(x_{0})=\max_{U}u(x)$. By the basic vector calculus, we can see:
    \begin{equation}
        \label{eq:one_order}
        Du(x_{0})=\mathbf{0},
    \end{equation}
    and 
    \begin{equation}
        \label{eq:two_order}
        D^{2}u(x_{0})\le 0.
    \end{equation}
    Mark that $D^{2}u(x_{0})\le 0$ means that the Hesse matrix $D^{2}u(x_{0})$ is semi negative definite. Since $A(x_{0})$ is symmetric and positive definite, there exists an orthogonal matrix $O$ such that 
    \begin{equation}
        OA(x_{0})O^{T}=D,
    \end{equation}
    while $D$ is a diagonal matrix. Now write $y=x_{0}+O(x-x_{0})$, i.e. $x-x_{0}=O^{T}(y-x_{0})$. Mark $O=(o_{ij})$, by the chain rule of derivatives:
    \begin{equation}
        u_{x_{i}}=\sum_{k=1}^{n}u_{y_{k}}o_{ki},u_{x_{i}x_{j}}=\sum_{k,l=1}^{n}u_{y_{k}y_{l}}o_{ki}o_{lj}.
    \end{equation}
    Then, at the point $x_{0}$,
    \begin{equation}
        \sum_{i,j}a^{ij}u_{x_{i}}u_{x_{j}}=\sum_{k,l}\sum_{i,j} a^{ij}u_{y_{k}y_{l}}o_{ki}o_{lj}=\sum_{i} d^{i}u_{y_{i}y_{i}}
    \end{equation}
    As $D^{2}u(x_{0})\le 0$, we can see $u_{y_{i}y_{i}}(x_{0})\le 0$, and for $A(x_{0})$ is positive definite, $d^{i}\ge 0$, i.e. 
    \begin{equation}
        \sum_{i,j}a^{ij}u_{x_{i}}u_{x_{j}}\le 0.
    \end{equation}
    On the other hand, at the point $x_{0}$:
    \begin{equation}
        \sum_{i=1}^{n}b^{i}u_{x_{i}}(x_{0})=\sum_{i=1}^{n}\sum_{k=1}^{n}u_{y_{k}}o_{ki}b^{i}=0.
    \end{equation}
    It means that $Lu(x_{0})\le 0$, contradict! So if $Lu<0$ in $U$, the maximum value of $u$ in $\bar{U}$ appears on $\partial U$.

    In general case, i.e. $Lu\le 0$, we derive the auxiliary function $u^{\epsilon}(x)=u(x)+\epsilon e^{\lambda x_{1}}$, then:
    \begin{equation}
        \begin{aligned}
            Lu^{\epsilon}&=Lu+\epsilon L(e^{\lambda x_{1}})\\
            &\le \epsilon e^{\lambda x_{1}}(-\lambda^{2}a^{11}+\lambda b^{1})\\
            &\le \epsilon e^{\lambda x_{1}}(-\lambda^{2}\theta+\lambda\norm{b}_{L^{\infty}}).
        \end{aligned}
    \end{equation}
    if we choose sufficiently large $\lambda$, we can see $Lu^{\epsilon}<0$ for any $\epsilon>0$. By the proof above, $u^{\epsilon}$ gets its maximum on $\partial U$. Let $\epsilon\rightarrow 0$, we can see $u$ gets its maximum on $\partial U$.
\end{proof}
\begin{remark}
    \begin{itemize}
        \item Maximum principle shows an important property for elliptic operator $L$.
        \item Since $-u$ is a subsolution whenever $u$ is a supersolution, if $Lu\ge 0$ in $U$, we can see $\min_{\bar{U}}u=\min_{\partial U}u.$
        \item Write $u^{+}=\max(u,0)$, if $c\ge 0$ and $Lu\le 0$ in $U$, we can see $\max_{\bar{U}}u\le\max_{\partial U}u^{+}$. Just consider the operator $K=L-cI$ to prove it.
    \end{itemize}
\end{remark}
\subsection{Strong maximum principle}
In this section, we establish the stronger result known as the strong maximum principle. In Theorem \ref{thm:WMP}, we prove that $u$ attains its maximum on the boundary $\partial U$. In fact, if there exists $x_0 \in U$ such that $u(x_0) = \max_{\bar{U}} u(x)$, then $u(x)$ must be constant, which is referred to as the \textbf{strong maximum principle}. First, we should introduce the \textbf{Hopf's lemma}, which derives a subtle analysis of the outer normal derivative $\pdfFrac{u}{\nu}$.
\begin{lemma}{Hopf's Lemma}
    \label{lem:Hopf}
    Assume $u\in C^{2}(U)\cap C^{1}(\bar{U})$ and $c\equiv 0$ in $U$, suppose further $Lu\le 0$ in $U$ and there exists $x^{0}\in\partial U$ such that 
    \begin{equation}
        u(x^{0})>u(x)
    \end{equation}
    for all $x\in U$. Assume finally that $U$ satisfies the interior ball condition at $x^{0}$, that is, there exists an open ball $B\subset U$ with $x^{0}\in\partial B$.
    \begin{itemize}
        \item Then, $\pdfFrac{u}{\nu}(x^{0})>0$ where $\nu$ is the outer unit normal to $B$ at $x^{0}$.
        \item If $c\ge 0$ in $U$, the same conclusion holds provided $u(x^{0})\ge 0$.
    \end{itemize} 
\end{lemma}
\begin{remark}  
    \begin{itemize}  
      \item The inequality $\frac{\partial u}{\partial \nu}(x^{0})\geq 0$ is trivial, so the strict inequality is necessary.  
      \item If the boundary $\partial U$ is $C^{2}$, the interior ball condition is satisfied.  
      \item The idea of this proof is to construct an auxiliary function $v$ that satisfies the following conditions:  
        \begin{itemize}  
          \item $v|_{\partial B}=0$,  
          \item $Lv\leq 0$,  
          \item $\frac{\partial v}{\partial \nu}(x^{0})<0$.  
        \end{itemize}  
    \end{itemize}  
\end{remark}  
\begin{proof}
    Consider the case $c\ge 0$. Without loss of generality, assume the center of the ball $B$ is the origin point, and we write $B=B(0,r)$. Set the auxiliary function 
    \begin{equation}
        v(x)=e^{-\lambda |x|^{2}}-e^{-\lambda r^{2}},
    \end{equation}
    first verify the three properties above. On $\partial B$, $|x|=r$ means that $\forall x\in \partial B$, $v(x)=0$. Then derive the expression of $Lv$:
    \begin{equation}
        \label{eq:calc_Lv}
        \begin{aligned}
            Lv&=-\sum a^{ij}v_{x_{i}x_{j}}+\sum b^{i}v_{x_{i}}+cv\\
            &=-\sum a^{ij}(x)4\lambda^2 e^{-\lambda|x|^{2}}x_{i}x_{j}+2\lambda e^{-\lambda |x|^2}\sum a^{ii}(x)-2\lambda\sum_{i=1}^{n}b^{i}e^{-\lambda|x|^2}+c(e^{-\lambda|x|^2}-e^{-\lambda r^{2}})\\
            &\le e^{-\lambda|x|^2}\left(-4\theta \lambda^{2}|x|^{2}+2\lambda\text{tr}(A)+2\lambda\norm{b}_{L^{\infty}}|x|+c\right).
        \end{aligned}
    \end{equation}
    Choose $\lambda$ sufficiently large, we can see $Lv\le 0$ for $x\in B(0,r)\setminus B(0,\frac{r}{2})$. Mark $u^{\epsilon}(x):=u(x)+\epsilon v(x)-u(x^{0})$, we can see $Lu^{\epsilon}(x)\le -cu(x^{0})\le 0$.

    By the equation $u(x^{0})>u(x)$, we can choose sufficiently small $\epsilon>0$ such that 
    \begin{equation}
        u^{\epsilon}(x)\le u^{\epsilon}(x^{0})=0
    \end{equation}
    on $\partial B(0,\frac{r}{2})$. As $v(x)=0$ on $\partial B(0,r)$, $u^{\epsilon}(x)\le 0$ for $x\in \partial B(0,r)$. By theorem \ref{thm:WMP}, $u^{\epsilon}(x)\le 0$ for all $x\in B(0,r)\setminus B(0,\frac{r}{2})$. And $u^{\epsilon}(x^{0})=0$, so we can see:
    \begin{equation}
        \pdfFrac{u^{\epsilon}}{\nu}(x^{0})\ge 0.
    \end{equation}
    Consequently:
    \begin{equation}
        \pdfFrac{u}{\nu}(x^{0})\ge -\epsilon\pdfFrac{v}{\nu}(x^{0})=-\frac{\epsilon}{r}Dv(x^{0})\cdot x^{0}=2\lambda\epsilon r e^{-\lambda r^{2}}>0.
    \end{equation}
\end{proof}
\begin{remark}
    \begin{itemize}
    \item If $c\equiv 0$, we don't require $u(x^{0})\ge 0$, because $Lu^{\epsilon}\le 0$ is true for $u(x^{0})<0$.
    \item If we write $u^{\epsilon}(x)=u(x)+\epsilon v(x)$, we can see that $Lu^{\epsilon}\le 0$ as well, and $\max_{\partial B(0,\frac{r}{2})\cup \partial B(0,r)}u^{\epsilon}(x)=u(x^{0})$. By remark 3 of theorem \ref{thm:WMP}, if $u(x^{0})\ge 0$, we can see $u^{\epsilon}(x)\le u(x^{0})$ as well; but if $u(x^{0})<0$, we can only derive $u^{\epsilon}(x)\le 0$. So, for $c\ge 0$, the condition $u(x^{0})\ge 0$ is necessary.
    \end{itemize}
\end{remark}

Hopf's lemma is the primary technical tool in the next proof:
\begin{theorem}{Strong maximum principle}
    \label{thm:SMP}
    Assume $u\in C^{2}(U)\cap C^{1}(\bar{U})$ and $c\equiv 0$ in $U$, suppose also $U$ is connected, open and bounded. If $Lu\le 0$ in $U$ and $u$ attains its maximum over $\bar{U}$ at an interior point, then $u$ is constant within $U$.
\end{theorem}
\begin{remark}
Theorem \ref{thm:SMP} is strictly stronger than theorem \ref{thm:WMP}. If $L$ satisfies the strong maximum principle, then the maximum of the function $u$ must be attained on the boundary $\partial U$. However, it should be noted that $\max_{U}u=\max_{\bar{U}}u$ does not imply that if $u$ attains its maximum value in $U$, then $u$ is constant.
\end{remark}
\begin{proof}
    Write $M=\max_{\bar{U}}u$ and $C:=\{x\in U|u(x)=M\}$, assume that $C\neq\emptyset$. Then if $u\not\equiv M$, set 
    \begin{equation}
        V:=\{x\in U|u(x)<M\},
    \end{equation}
    then choose $y\in V$ such that $\text{dist}(y,C)<\text{dist}(y,\partial U)$, and let $B$ denote the largest ball with center $y$ whose interior lies in $V$, then there exists $x^{0}\in C\cap \partial B$. By Hopf's lemma, $\pdfFrac{u}{\nu}(x^{0})>0$. But on the other hand, $x^{0}\in C$ means $Du(x^{0})=\mathbf{0}$, contradict!
\end{proof}
\begin{remark}
    If $c\ge 0$, $Lu\le 0$ in $U$, and $u$ attains its \textbf{non-negative} maximum over $\bar{U}$ at an interior point, then $u$ is constant within $U$.
\end{remark}
\section{Harnack's Inequality}
Harnack's inequality states that the values of a nonnegative solution are comparable, i.e. if $u\ge 0$ and $u$ is the solution of elliptic equation $Lu=0$, the supremum of function $u$ can be controled by its infimum.
\begin{theorem}{Harnack's inequality}
    Assume $u\ge 0$ is a $C^{2}$ solution of $Lu=0$ in $U$, and suppose $V\subset\subset U$ is connected. Then there exists a constant $C$ such that 
    \begin{equation}
        \sup_{V}u\le C\inf_{V}u.
    \end{equation}
    The constant $C$ depends only on $V$ and the coefficients of $L$.
\end{theorem}
\textbf{The idea of this proof:} Without loss of generality, we assume that $u>0$ in $U$. Set $v(x):=\log u(x)$, choose $x\in V$, $y\in V$ and $x\neq y$, as $V$ is connected, there is a path comes through the point $x$ and $y$, marked as $l$. As $l$ is compact, there exists finite number of balls $B(x_{i},r_{i})$ such that $l\subset\cup_{i=1}^{N}B(x_{i},r_{i})$. If $\norm{Dv}_{L^{\infty}(V)}<\infty$, on the ball $B(x_{i},r_{i})$, choose $x,y\in B(x_{i},r_{i})\cap l$, we can see that 
\begin{equation}
    |v(x)-v(y)|\le N|Dv|r\le CNr,
\end{equation}
while $r$ means the length of the arc from $x$ to $y$. As the cover is finite, mark the arc length of $l$ is $s_{xy}$, we can see:
\begin{equation}
    \left|\frac{u(x)}{u(y)}\right|\le e^{|v(x)-v(y)|}\le e^{CNs_{xy}}\le C(V).
\end{equation}
So, it suffices to show that $\norm{Dv}_{L^{\infty}(V)}<\infty$.
\begin{proof}
    We just consider a simple case, i.e. $a^{ij}\in C^{\infty}(U)$ and $b^{i}\equiv 0, c\equiv 0$. As $u$ is the solution, we can see $\sum a^{ij}u_{x_{i}x_{j}}=0$, i.e. 
    \begin{equation}
        \label{eq:aux_v_satisfy}
        \sum a^{ij}v_{x_{i}x_{j}}+a^{ij}v_{x_{i}}v_{x_{j}}=0.
    \end{equation}
    Then derive the expression for:
    \begin{equation}
        \label{eq:Dij}
        a^{ij}D_{i}D_{j}|Dv|^{2}=\sum_{k=1}^{n}2a^{ij}(D_{i}D_{k}vD_{j}D_{k}v+D_{k}vD_{i}D_{j}D_{k}v).
    \end{equation}
    By \eqref{eq:aux_v_satisfy}, we can see:
    \begin{equation}
        \label{eq:diff_aux_v}
        \sum_{i,j=1}^{n}\left(D_{k}a^{ij}v_{x_{i}x_{j}}+a^{ij}v_{x_{i}x_{j}x_{k}}+D_{k}a^{ij}D_{i}vD_{j}v+2a^{ij}D_{k}D_{i}vD_{j}v\right)=0.
    \end{equation}
    Combine \eqref{eq:diff_aux_v} and \eqref{eq:Dij}, we can see:
    \begin{equation}
        \begin{aligned}
        \sum a^{ij}D_{i}D_{j}|Dv|^{2}&=\sum\left(2a^{ij}D_{i}D_{k}vD_{j}D_{k}v-2D_{k}vD_{k}a^{ij}\left(D_{i}D_{j}v+D_{i}vD_{j}v\right)-4D_{k}va^{ij}D_{k}D_{i}vD_{j}v\right)\\
        &=\sum\left(2a^{ij}D_{i}D_{k}vD_{j}D_{k}v-2D_{k}vD_{k}a^{ij}\left(D_{i}D_{j}v+D_{i}vD_{j}v\right)-2a^{ij}D_{i}|Dv|^{2}D_{j}v\right).
        \end{aligned}
    \end{equation}
    To be continued...
\end{proof}
\section{Eigenvalues and Eigenfunctions}
In this section, we consider the boundary-value problem:
\begin{equation}
    \label{eq:eig-value_prob}
    \left\{
        \begin{aligned}
            Lw&=\lambda w,x\in U;\\
            w&=0,x\in\partial U,
        \end{aligned}
    \right.
\end{equation}
where $U$ is open and bounded, and we call $\lambda$ an \textbf{eigenvalue} of $L$ with a nontrivial \textbf{eigenfunction} $w$. Now, we will discuss the properties of operator $L$, its eigenvalues $\lambda$ and the corresponding eigenfunctions $w$.
\subsection{Eigenvalues of symmetric elliptic operators}
For simplicity, we consider now an elliptic operator having the divergence form:
\begin{equation}
    \label{eq:symmetric_elliptic}
    Lu=-\sum_{i,j=1}^{n}\left(a^{ij}u_{x_{i}}\right)_{x_{j}},
\end{equation}
where $a^{ij}\in C^{\infty}(\bar{U})$. We suppose the coefficients $a^{ij}$ satisfy the symmetry condition $a^{ij}=a^{ji}$, then the operator $L$ is thus formally \textbf{symmetric}, and in particular the associated bilinear form $B[\;,\;]$ satisfies $B[u,v]=B[v,u]$. Assume also $U$ is connected.
\begin{theorem}{Eigenvalues of symmetric elliptic operators}
    \label{thm:eig_val_of_sym_op}
    For the operator $L$ as \eqref{eq:symmetric_elliptic}:
    \begin{itemize}
        \item Each eigenvalue of $L$ is real.
        \item If we repeat each eigenvalue according to its (finite) multiplicity, we have:
        \begin{equation}
            \label{eq:spectrum}
            \Sigma=\{\lambda_{k}\}_{k=1}^{\infty}
        \end{equation}
        where 
        \begin{equation}
            0<\lambda_1\le\lambda_2\le\cdots
        \end{equation}
        and $\lim_{k\rightarrow\infty}\lambda_{k}=\infty$.
        \item Finally, there exists an orthonormal basis $\{w_{k}\}_{k=1}^{\infty}$ of $L^{2}(U)$, where $w_{k}\in H_{0}^{1}(U)$ is an eigenfunction corresponding to $\lambda_{k}$:
        \begin{equation}
            \left\{
                \begin{aligned}
                    Lw_{k}&=\lambda_{k}w_{k},x\in U\\
                    w_{k}&=0,x\in\partial U.
                \end{aligned}
            \right.
        \end{equation}
    \end{itemize}
\end{theorem}
\begin{remark}
    Owing to the regularity theorem, $w_{k}\in C^{\infty}(U)$, and furthermore $\omega_{k}\in C^{\infty}(\bar{U})$ if $\partial U$ is smooth.
\end{remark}
\begin{proof}
    First, by the form of operator $L$, we can see the corresponding bilinear form $B[u,v]$ of $L$ is \textbf{bounded} and \textbf{uniformly elliptic}. By the discussion about theorem \ref{thm:2nd_exist}, the operator $L$ is a linear, bounded bijective from $L^{2}(U)$ to $L^{2}(U)$, and its inverse operator $S:=L^{-1}$ is a compact operator.

    Then, claim that $S$ is symmetric. First, if $Sf=u$, it means that 
    \begin{equation}
        \label{eq:Sf}
        \left\{
            \begin{aligned}
                Lu&=f,x\in U;\\
                u&=0,x\in\partial U,\\
            \end{aligned}
        \right.
    \end{equation}
    and if $Sg=v$, it means that 
    \begin{equation}
        \label{eq:Sg}
        \left\{
            \begin{aligned}
                Lv&=g,x\in U;\\
                v&=0,x\in\partial U,\\
            \end{aligned}
        \right.
    \end{equation}
    then 
    \begin{equation}
        (Sf,g)=(u,g)=(u,Lv)=(Lv,u)=B[v,u],
    \end{equation}
    and 
    \begin{equation}
        (f,Sg)=(f,v)=(Lu,v)=B[u,v],
    \end{equation}
    as $B[u,v]=B[v,u]$, i.e. $(Sf,g)=(f,Sg)$, so $S$ is symmetric.

    Notice that $(Sf,f)=(u,f)=(u,Lu)=B[u,u]\ge 0$, we can see $S$ is a positive operator. Then: we can see $S$ is \textbf{compact, symmetric, linear and positive}. By the property of compact and positive operator, we can see the eigenvalues of $S$ are all real, $\eta_{k}\rightarrow 0$, and the eigenvectors of $S$, marked as $\{w_{k}\}$, form an orthonormal basis of $L^{2}(U)$. As $S=L^{-1}$, $w_{k}$ is also the eigenfunction of $L$ with eigenvalue $\frac{1}{\eta_{k}}$. So the eigenvalues of $L$ satisfies $\lim_{k\rightarrow\infty}\lambda_{k}=\infty$, and the eigenfunctions $\{w_{k}\}$ form an orthonormal basis for $L^{2}(U)$.
\end{proof}
\begin{remark}
    Specially, if $L=-\Delta$, and the region $U\subset\mathbb{R}^{n}$ is bounded and open, \textbf{Weyl's Law} asserts
    \begin{equation}
        \lim_{k\rightarrow\infty}\frac{\lambda_{k}^{\frac{n}{2}}}{k}=\frac{(2\pi)^{n}}{|U|\alpha(n)}. 
    \end{equation}
\end{remark}
Now, we scrutinize more carefully the \textbf{first eigenvalue} of $L$.
\begin{definition}
    We call $\lambda_{1}>0$ the principal eigenvalue of $L$.
\end{definition}
\begin{theorem}{Variational principle for the principal eigenvalue}
    \label{thm:variational_principle}
    \begin{itemize}
        \item We have 
        \begin{equation}
            \label{eq:principal_eig_value}
            \lambda_{1}=\min\{B[u,u]|u\in H_{0}^{1}(U),\norm{u}_{L^{2}}=1\}.
        \end{equation}
        \item Furthermore, the above minimum is attained for a function $w_{1}$, positive within $U$, which solves 
        \begin{equation}
            \label{eq:eig_func_for_principal_eig}
            \left\{
                \begin{aligned}
                Lw_{1}&=\lambda_{1}w_{1},x\in U;\\
                w_{1}&=0,x\in\partial U.\\
                \end{aligned}
            \right.
        \end{equation}
        \item Finally, if $u\in H_{0}^{1}(U)$ is any weak solution of 
        \begin{equation}
            \left\{
                \begin{aligned}
                    Lu&=\lambda_{1}u,x\in U;\\
                    u&=0,x\in\partial U,
                \end{aligned}
            \right.
        \end{equation}
        then $u$ is a multiple of $w_{1}$.
    \end{itemize}
\end{theorem}
\begin{remark}
    Theorem \ref{thm:variational_principle} suggests that the principal eigenvalue $\lambda_{1}$ is simple. 
\end{remark}
\begin{proof}
    First, define $B[\;,\;]$ as an inner product in $H_{0}^{1}(U)$, find the \textbf{orthonormal basis} of the Hilbert space $H_{0}^{1}(U)$. By theorem \ref{thm:eig_val_of_sym_op}, the eigenfunctions $\{w_{k}\}$ form an orthonormal basis on $L^{2}(U)$, $\norm{w_{k}}_{L^{2}(U)}=1$, and 
    \begin{equation}
        \begin{aligned}
        B[w_{k},w_{k}]&=\lambda_{k}\norm{w_{k}}_{L^{2}(U)}^{2}=\lambda_{k},\\
        B[w_{k},w_{l}]&=0(k\neq l),\\
        \end{aligned}
    \end{equation}
    so the set $\left\{\frac{w_{k}}{\lambda_{k}^{\frac{1}{2}}}\right\}_{k=1}^{\infty}$ forms an orthonormal subset of $H_{0}^{1}(U)$. Then we show this orthonormal subset is complete. Assume $u\in H_{0}^{1}(U)$ satisfies
    \begin{equation}
        B[u,w_{k}]=0,k=1,2,\cdots,
    \end{equation}
    as $\{w_{k}\}$ is an orthonormal basis in $L^{2}(U)$, by Fourier expansion:
    \begin{equation}
        u=\sum_{k=1}^{\infty}(u,w_{k})w_{k}:=\sum_{k=1}^{\infty}d_{k}w_{k}.
    \end{equation}
    Then $B[u,w_{k}]=0$ means that $\lambda_{k}d_{k}=0$, i.e. $d_{k}\equiv 0$, so $u\equiv 0$. Now the set $\left\{\frac{w_{k}}{\lambda_{k}^{\frac{1}{2}}}\right\}$ forms an orthonormal basis for $H_{0}^{1}(U)$ equipped with inner product $B[\;,\;]$.

    Now, recall the expression $B[u,u]$. If $\norm{u}_{L^{2}(U)}=1$, write the Fourier expansion \textbf{on space $H_{0}^{1}(U)$} as $u=\sum_{k=1}^{\infty} d_{k}w_{k}$, with $\sum_{k=1}^{\infty} d_{k}^{2}=1$, we can see:
    \begin{equation}
        B[u,u]=B[\sum d_{k}w_{k},\sum d_{k}w_{k}]=\sum d_{k}^{2}\lambda_{k}\ge\lambda_{1},
    \end{equation}
    and the equality holds for $u=w_{1}$. We complete the proof of \eqref{eq:principal_eig_value}. 

    Then, if $u$ satisfies \eqref{eq:eig_func_for_principal_eig}, i.e. $Lu=\lambda_{1}u$, and $\norm{u}_{L^{2}(U)}=1$, we can see $B[u,u]=(Lu,u)=\lambda_{1}\norm{u}_{L^{2}(U)}^{2}=\lambda_{1}$. On the other hand, if $B[u,u]=1$ and $\norm{u}_{L^{2}(U)}=1$, consider the Fourier series of $u$ as $u=\sum d_{k}u_{k}$ with $\sum d_{k}^{2}=1$, we have 
    \begin{equation}
        \sum d_{k}^{2}\lambda_{1}=\lambda_{1}=B[u,u]=\sum d_{k}^{2}\lambda_{k}.
    \end{equation}
    i.e. for $k\ge 2$, $d_{k}=(u,w_{k})=0$. By \textbf{Fredholm alternative}, the eigenvalue $\lambda_{1}$ has finite multiplicity, it follows that 
    \begin{equation}
        u=\sum_{k=1}^{m}(u,w_{k})w_{k}
    \end{equation}
    for $m<\infty$ and $Lw_{k}=\lambda_{1}w_{k}$. Therefore:
    \begin{equation}
        Lu=\sum_{k=1}^{m}(u,w_{k})Lw_{k}=\lambda_{1}u.
    \end{equation}

    Finally, we will show that the multiplicity of eigenvalue $\lambda_{1}$ is $1$. To show this result, we should derive the following lemma:
    \begin{lemma}
        If $u\in H_{0}^{1}(U)$ is a weak solution of \eqref{eq:eig_func_for_principal_eig}, $u\not\equiv 0$, then either $u>0$ in $U$ or $u<0$ in $U$.
    \end{lemma}
    \begin{proof}
        Without loss of generality, assume $\norm{u}_{L^{2}(U)}=1$, mark $\alpha=\int_{U}(u^{+})^{2}\dif x$, $\beta=\int_{U}(u^{-})^{2}\dif x$, we can see $\alpha+\beta=1$. Then:
        \begin{equation}
            \lambda_{1}=B[u,u]=B[u^{+},u^{+}]+B[u^{-},u^{-}]\ge \lambda_{1}(\alpha+\beta)=\lambda_{1}.
        \end{equation}
        The equality holds, so $B[u^{+},u^{+}]=\lambda_{1}\norm{u^{+}}_{L^{2}(U)}^{2}$, and $B[u^{-},u^{-}]=\lambda_{1}\norm{u^{-}}_{L^{2}(U)}^{2}$. It means that $u^{+}$ and $u^{-}$ are both the weak solution of $Lu=\lambda_{1}u$. What's more, $Lu^{+}\ge 0$, by strong maximum principle, $u^{+}>0$ in $U$ or $u^{+}\equiv 0$ in $U$. Similar arguments apply to $u^{-}$. So either $u>0$ in $U$ or $u<0$ in $U$.
    \end{proof}
    Back to the proof of main theorem. If $u$ and $\tilde{u}$ are both nontrivial solution of equation \eqref{eq:eig_func_for_principal_eig}, by the above lemma, $\int_{U}u\dif x\neq 0$ and $\int_{U}\tilde{u}\dif x\neq 0$. So $\exists k\in\mathbb{R}$ such that $\int_{U}(u-k\tilde{u})\dif x=0$. On the other hand, $u-k\tilde{u}$ still satisfies equation \eqref{eq:eig_func_for_principal_eig} and $\int_{U}(u-k\tilde{u})\dif x=0$, by the above lemma, we can see $u-k\tilde{u}\equiv 0$. So $u=k\tilde{u}$ in $U$. Hence the eigenvalue $\lambda_{1}$ is simple.
\end{proof}
\section{Eigenvalues of nonsymmetric elliptic operators}
Now consider a uniformly elliptic operator $L$ in the nondivergence form:
\begin{equation}
    Lu=-\sum_{i,j=1}^{n}a^{ij}u_{x_{i}x_{j}}+\sum_{i=1}^{n}b^{i}u_{x_{i}}+cu.
\end{equation}
Suppose that $a^{ij},b^{i},c\in C^{\infty}(\bar{U})$ and $U$ is open, bounded and connected, assume $a^{ij}=a^{ji}$ and $c\ge 0$ in $U$. In this condition, the operator $L$ is no longer symmetry, i.e. $L$ will in general have complex eigenvalues and eigenfunctions. However, there are still some properties about the principal eigenvalue of $L$.
\begin{theorem}{Principal eigenvalue for nonsymmetric elliptic operators}
    \begin{itemize}
        \item There exists a real eigenvalue $\lambda_{1}$ for the operator $L$, taken with zero boundary conditions, such that if $\lambda\in\mathbb{C}$ is any other eigenvalue, we have $\Re(\lambda)\ge\lambda_{1}$.
        \item There exists a corresponding eigenfunction $w_{1}$, which is positive within $U$.
        \item The eigenvalue $\lambda_{1}$ is simple.
    \end{itemize}
\end{theorem}
\begin{proof}
    skip.
\end{proof}
\section{Exercises}
\begin{exercise}
    $u\in H^{1}(\mathbb{R}^{n})$ have compact support and be a weak solution of 
    \begin{equation}
        -\Delta u+c(u)=f,
    \end{equation}    
    where $f\in L^{2}(\mathbb{R}^{n})$, $c:\mathbb{R}\rightarrow\mathbb{R}$ smooth, $c(0)=0$, $c'(0)\ge 0$, and $c(u)\in L^{2}(\mathbb{R}^{n})$. Derive the estimate:
    \begin{equation}
        \norm{D^{2}u}_{L^{2}(\mathbb{R}^{n})}\le C\norm{f}_{L^{2}(\mathbb{R}^{n})}.
    \end{equation}
\end{exercise}
\begin{solution}
    Assume $\text{supp}u=\Omega$ is a convex compact subset of $\mathbb{R}^{n}$, by the definition of weak solution, $\forall v\in H_{0}^{1}(\Omega)$, we have:
    \begin{equation}
        \label{eq:weak_form}
        \int_{\Omega}-\Delta uv+c(u)v\dif x=\int_{\Omega}fv\dif x.
    \end{equation}
    By Gauss-Green formula and $v=0$ on $\partial\Omega$, we can see:
    \begin{equation}
        \label{eq:modified_form}
        \int_{\Omega}\nabla v\cdot\nabla u\dif x=\int_{\Omega}(f-c(u))v\dif x.
    \end{equation}
    Mark $A:=\int_{\Omega}\nabla v\cdot\nabla u\dif x$, $B:=\int_{\Omega}(f-c(u))v\dif x$, and choose $v=-D_{k}^{-h}\left(D_{k}^{h}u\right)(1\le k\le n)$, we can see:
    \begin{equation}
        \label{eq:approx_A}
        \begin{aligned}
            A&=\sum_{i=1}^{n}\int_{\Omega}v_{x_{i}}u_{x_{i}}\dif x\\
            &=-\sum_{i=1}^{n}\int_{\Omega}\left(D_{k}^{-h}\left(D_{k}^{h}u\right)\right)_{x_{i}}u_{x_{i}}\dif x\\
            &=\sum_{i=1}^{n}\int_{\Omega}\left(D_{k}^{h}u\right)_{x_{i}}\left(D_{k}^{h}u\right)_{x_{i}}\dif x\\
            &=\norm{D_{k}^{h}Du}_{L^2}^2.
        \end{aligned}
    \end{equation} 
    Then mark $B_{1}:=\int_{\Omega}fv\dif x$, $B_{2}:=-\int_{\Omega}c(u)v\dif x$, we can see $B=B_{1}+B_{2}$. By Cauchy-Schwarz inequality:
    \begin{equation}
        \label{eq:approx_B1}
        B_{1}\le \norm{f}_{L^2}\norm{v}_{L^2}\le C\norm{f}_{L^2}\norm{D_{k}^{h}Du}_{L^2}.
    \end{equation}
    And:
    \begin{equation}
        \label{eq:approx_B2}
        \begin{aligned}
            B_{2}=-\int_{\Omega}c(u)v\dif x&=-\int_{\Omega}D_{k}^{h}(c(u))D_{k}^{h}u\dif x\\
            &=-\int_{\Omega}\frac{u(x+he_{k})-u(x)}{h}\frac{c(u(x+he_{k}))-c(u(x))}{h}\dif x\\
            &=-\int_{\Omega}\left(\frac{u(x+he_{k})-u(x)}{h}\right)^2c'(\xi(x))\dif x\\
            &\le 0,
        \end{aligned}
    \end{equation}
    while the third equality holds from the mean value theorem on convex region, and the final inequality holds from the condition $c'\ge 0$.

    So: $\forall 1\le k\le n$, we can see:
    \begin{equation}
        \norm{D_{k}^{h}Du}_{L^2}\le C_{k}\norm{f}_{L^{2}}.
    \end{equation}
    Set $h\rightarrow 0$, we can derive the result 
    \begin{equation}
        \norm{D^{2}u}_{L^2}\le C\norm{f}_{L^2}.
    \end{equation}
\end{solution}
\begin{exercise}
    Assume $u$ is a smooth solution of $Lu=-\sum_{i,j=1}^{n}a^{ij}u_{x_{i}x_{j}}=f$ in $U$, $u=0$ on $\partial U$, where $f$ is bounded. Fix $x^{0}\in\partial U$. A barrier at $x^{0}$ is a $C^{2}$ function $w$ such that
    \begin{equation}
        Lw\ge 1(x\in U),w(x^{0})=0,w\ge 0(x\in\partial U).
    \end{equation}
    Show that if $w$ is a barrier at $x^{0}$, there exists a constant $C$ such that:
    \begin{equation}
        |Du(x^{0})|\le C\left|\pdfFrac{w}{\nu}(x^{0})\right|.
    \end{equation}
\end{exercise}
\begin{solution}
    First, set $\varphi_{1}:=u+w\norm{f}_{L^{\infty}}$, we can see:
    \begin{equation}
        L\varphi_{1}=f+\norm{f}_{\infty}Lw\ge 0,
    \end{equation}
    and $\varphi_{1}|_{\partial\Omega}\ge 0$. By weak maximum principle, $\min_{\bar{U}}\varphi_{1}=0$. 

    Then, set $\varphi_{2}:=u-w\norm{f}_{L^{\infty}}$, we can see:
    \begin{equation}
        L\varphi_{2}=f-\norm{f}_{\infty}Lw\le 0,
    \end{equation}
    and $\varphi_{2}|_{\partial\Omega}\le 0$. By weak maximum principle, $\max_{\bar{U}}\varphi_{2}=0$. By Hopf's lemma, $\pdfFrac{\varphi_{1}}{\nu}(x_{0})\le 0$, $\pdfFrac{\varphi_{2}}{\nu}(x_{0})\ge 0$.

    What's more, $u|_{\partial\Omega}=0$, i.e. $\nabla u\parallel \nu$. So there exists $C>0$ such that 
    \begin{equation}
        |Du(x_{0})|\le C\left|\pdfFrac{w}{\nu}(x_{0})\right|.
    \end{equation}
\end{solution}
\begin{exercise}
    Assume $U$ is connected. Use (a) energy methods and (b) the maximum principle to show that the only smooth solutions of the Neumann boundary-value problem
    \begin{equation}
        \left\{
            \begin{aligned}
                -\Delta u&=0,x\in U;\\
                \pdfFrac{u}{\nu}&=0,x\in\partial U
            \end{aligned}
        \right.
    \end{equation}
    are $u\equiv C$, for some constant $C$.
\end{exercise}
\begin{solution}
    (a)Energy method: as $\Delta u=0$ and $\left.\pdfFrac{u}{\nu}\right|_{\partial U}\equiv 0$, we can see:
    \begin{equation}
        0=-\int_{U}u\Delta u\dif x=\int_{U}|\nabla u|^{2}\dif x-\int_{U}u\pdfFrac{u}{\nu}\dif S=\int_{U}|\nabla u|^{2}\dif x.
    \end{equation}
    It means that $\nabla u\equiv 0$ a.e. And $u$ is smooth, so $u\equiv C$.

    (b)The maximum principle: First, we derive the WMP. Set $\varphi:=u+\epsilon |x|^{2}$, we can see $-\Delta\varphi=-\Delta u-\Delta(\epsilon |x|^2)=-2n\epsilon<0$, and $\pdfFrac{\varphi}{\nu}=\epsilon\pdfFrac{|x|^2}{\nu}>0$, then $\max_{\bar{U}}\varphi=\max_{\partial U}\varphi$, i.e.:
    \begin{equation}
        u(x)+\epsilon |x|^{2}\le\max_{x\in\partial U}u(x)+\epsilon d^{2},
    \end{equation}
    while $d$ is the diagram of region $U$. Choose $\epsilon\rightarrow 0$, we get the weak maximum principle (WMP) of $u$. Then derive the strong maximum principle. Set:
    \begin{equation}
        \begin{aligned}
            V&:=\{x\in U|u(x)<M\},\\
            C&:=\{x\in U|u(x)=M\},
        \end{aligned}
    \end{equation}
    choose $x\in V$, construct a ball $B(x)$ such that $B(x)\cap C=\{x^{0}\}$ or $B(x)\cap \partial U=\{x^{0}\}$. By Hopf's lemma, $\pdfFrac{u}{\nu}(x^{0})>0$. If $x^{0}\in\partial C$, contradict to $u(x)\equiv M$; if $x^{0}\in\partial U$, contradict to the boundary condition. So $u\equiv C$.
\end{solution}
\begin{exercise}
    Assume $u\in H^{1}(U)$ is a bounded weak solution of equation 
    \begin{equation}
        -\sum_{i,j}\left(a^{ij}u_{x_{i}}\right)_{x_{j}}=0,x\in U.
    \end{equation}
    Let $\phi:\mathbb{R}\rightarrow\mathbb{R}$ be convex and smooth, and set $w=\phi(u)$. Show $w$ is a weak subsolution, i.e. $B[w,v]\le 0$ for all $v\in H_{0}^{1}(U),v\ge 0$. 
\end{exercise}
\begin{solution}
    By the definition of weak solution, we can see:
    \begin{equation}
        \begin{aligned}
            B[\phi(u),v]&=\sum_{i,j}\int_{V}a^{ij}\phi'(u)u_{x_{i}}v_{x_{j}}\dif x\\
            &=\sum_{i,j}\int_{V}a^{ij}u_{x_{i}}\pdfFrac{(\phi'(u)v)}{x_{j}}\dif x-\sum_{i,j}\int_{V}a^{ij}u_{x_{i}}v\phi''(u)u_{x_{j}}\dif x\\
            &=-\sum_{i,j}\int_{V}a^{ij}u_{x_{i}}u_{x_{j}}v\phi''(u)\dif x\\
            &\le-\theta\int_{V}v\phi''(u)|\nabla u|^{2}\dif x\le 0.
        \end{aligned}
    \end{equation}
While the second equation follows from integration by parts, the third equation follows from the fact that $u$ is a bounded weak solution, and the final step comes from the uniform elliptic condition.
\end{solution}
\begin{exercise}
We say that the uniformly elliptic operator 
\begin{equation}
    Lu=-\sum a^{ij}u_{x_{i}x_{j}}+\sum b^{i}u_{x_{i}}+cu
\end{equation}
satisfies the weak maximum principle if for all $u\in C^{2}(U)\cap C^{1}(\bar{U})$, 
\begin{equation}
    \left\{
        \begin{aligned}
            Lu&\le 0,x\in U\\
            u&\le 0,x\in\partial U\\
        \end{aligned}
    \right.
\end{equation}
implies that $u\le 0$ in $U$. Suppose that there exists a function $v\in C^{2}(U)\cap C^{1}(\bar{U})$ such that $Lv\ge 0$ in $U$ and $v>0$ on $\bar{U}$. Show that $L$ satisfies the weak maximum principle.
\end{exercise}
\begin{solution}
    Set $w=\frac{u}{v}$, derive $a^{ij}w_{ij}$ as:
    \begin{equation}
        a^{ij}w_{ij}=a^{ij}\left[\frac{vu_{ij}-uv_{ij}}{v^2}+\frac{2uv_{i}v_{j}-2vu_{j}v_{i}}{v^3}+\frac{u_{j}v_{i}-u_{i}v_{j}}{v^2}\right].
    \end{equation}
    Sum them up, we can see:
    \begin{equation}
        \label{eq:auxiliary_op}
        -\sum a^{ij}w_{ij}=\sum\frac{ua^{ij}v_{ij}}{v^2}-\sum\frac{va^{ij}u_{ij}}{v^2}+\frac{2}{v^3}\sum\left(a^{ij}vu_{j}v_{i}-a^{ij}uv_{i}v_{j}\right).
    \end{equation}
    On the region $\{u>0\}$, by the condition $-\sum a^{ij}v_{ij}+\sum b^{i}v_{i}+cv>0$, $-\sum a^{ij}u_{ij}+\sum b^{i}u_{i}+cu\le 0$, then estimate \eqref{eq:auxiliary_op}, we have:
    \begin{equation}
        \begin{aligned}
            -\sum a^{ij}w_{ij}&\le \frac{u}{v^2}\left(\sum b^{i}v_{i}+cv\right)-\frac{1}{v}\left(\sum b^{i}u_{i}+cu\right)+\frac{2}{v^3}\sum a^{ij}v_{i}(vu_{j}-uv_{j})\\
            &=\sum \frac{b^{j}}{v^2}\left(uv_{j}-vu_{j}\right)-\frac{2}{v^{3}}\sum a^{ij}v_{i}\left(uv_{j}-vu_{j}\right)\\
            &=\sum\left(\frac{b^j}{v^2}-\frac{2}{v^3}\sum a^{ij}v_{i}\right)\left(uv_{j}-vu_{j}\right)\\
            &=\sum\left(\frac{2}{v}\sum a^{ij}v_{i}-b^{j}\right)w_{j}.
        \end{aligned}
    \end{equation} 
    So if we define:
    \begin{equation}
        Mw:=-\sum a^{ij}w_{ij}+\sum\left(b^{j}-\frac{2}{v}\sum a^{ij}v_{i}\right)w_{j},
    \end{equation}
    we can see $Mw\le 0$ on the region $\{u>0\}$. $L$ is uniformly elliptic means that $M$ is uniformly elliptic, so the operator $M$ satisfies weak maximum principle. If $\{u>0\}\neq\emptyset$, mark $\Omega:=\{x|u(x)>0\}$, $Mw\le 0$ means $0<\sup_{\bar{\Omega}}w=\sup_{\partial\Omega}w=0$, contradict!

    So $\Omega=\emptyset$, i.e. $L$ satisfies weak maximum principle.
\end{solution}
\begin{exercise}
    Let $Lu=-\sum_{i,j=1}^{n}\left(a^{ij}u_{x_{i}}\right)_{x_{j}}$, where $(a^{ij})$ is symmetric. Assume the operator $L$ with zero boundary conditions has eigenvalues $0<\lambda_{1}\le\lambda_{2}\le\cdots$.Show:
    \begin{equation}
        \label{eq:minimax}
        \lambda_{k}=\max_{S\in\Sigma_{k-1}}\min_{u\in S^{\bot},\norm{u}_{L^{2}}=1}B[u,u].
    \end{equation}
    Here $\Sigma_{k-1}$ means the collection of $(k-1)$-dimensional subspaces of $H_{0}^{1}(U)$.
\end{exercise}
\begin{solution}
    By theorem \ref{thm:eig_val_of_sym_op}, $\exists$ an orthogonal basis $\{u_{i}\}$ for Hilbert space $H_{0}^{1}(U)$, such that 
    \begin{equation}
        \begin{aligned}
            Lu_{i}&=\lambda_{i}u_{i},\\
            B[u_{i},u_{j}]&=\lambda_{i}\delta_{ij},\\
            \innerprod{u_{i}}{u_{j}}_{L^{2}(U)}&=\delta_{ij}.\\
        \end{aligned}
    \end{equation} 
    Assume $\norm{u}_{L^{2}}=1$, write $u=\sum r_{i}u_{i}$, we can see $\sum r_{i}^{2}=1$. Then:
    \begin{equation}
        B[u,u]=B\left[\sum r_{i}u_{i},\sum r_{i}u_{i}\right]=\sum\lambda_{i}r_{i}^{2}.
    \end{equation}
    Set the subspace $S_{0}:=\text{sp}\{u_{1},\cdots,u_{k-1}\}$, $S_{1}:=\text{sp}\{u_{1},\cdots,u_{k}\}$, then $S^{\bot}\cap S_{1}\neq\emptyset$. Choose $\tilde{u}\in S^{\bot}\cap S_{1}$, we can see 
    \begin{equation}
        B[\tilde{u},\tilde{u}]=\sum_{i=1}^{k}\lambda_{i}r_{i}^{2}\le\lambda_{k}.
    \end{equation}
    So the right hand of equation \eqref{eq:minimax} is less or equal to $\lambda_{k}$. On the other hand, if we choose $\Sigma_{k-1}=S_{0}$, as $B[u_{k},u_{k}]=\lambda_{k}$, the "=" can be satisfied. Now, we complete the proof.
\end{solution}
\begin{exercise}
    Let $\lambda_{1}$ be the principal eigenvalue of the uniformly elliptic, nonsymmetric operator
    \begin{equation}
        Lu=-\sum a^{ij}u_{x_{i}x_{j}}+\sum b^{i}u_{x_{i}}+cu,
    \end{equation}
    taken with zero boundary conditions. Prove the max-min representation formula 
    \begin{equation}
        \lambda_{1}=\sup_{u}\inf_{x}\frac{Lu(x)}{u(x)},
    \end{equation}
    the "sup" taken over functions $u\in C^{\infty}(\bar{U})$ with $u>0$ in $U$, $u=0$ on $\partial U$, and the "inf" taken over points $x\in U$.
\end{exercise}
\begin{solution}
    Set $X:=\{u\in C^{\infty}(\bar{U}):u>0(x\in U),u=0(x\in\partial U)\}$. Assume $w_{1}\in H^{1}(U)$, $w_{1}>0$ is the eigenfunction related to $\lambda_{1}$, choose $\{u_{n}\}\subset X$ such that $u_{n}\rightarrow w_{1}$ in $H^{1}(U)$, then 
    \begin{equation}
    \sup_{u}\inf_{x}\frac{Lu(x)}{u(x)}\ge\inf_{x}\frac{Lu_{n}(x)}{u_{n}(x)}.
    \end{equation}
    Set $n\rightarrow\infty$, we can see that 
    \begin{equation}
        \sup_{u}\inf_{x}\frac{Lu(x)}{u(x)}\ge\lambda_{1}.
    \end{equation}
    Then it suffices to show $\sup_{u}\inf_{x}\frac{Lu(x)}{u(x)}\le\lambda_{1}$, i.e. $\inf_{x\in U}(Lu-\lambda_{1}u)\le 0$. As $\lambda_{1}\in\mathbb{R}$, by the definition of dual operator, $\lambda_{1}$ is also the principal eigenvalue of operator $L^{*}$, i.e. $\exists w_{1}^{*}>0$ such that $L^{*}w_{1}^{*}=\lambda_{1}w_{1}^{*}$. Then:
    \begin{equation}
        \innerprod{Lu-\lambda_{1}u}{w_{1}^{*}}=\innerprod{u}{L^{*}w_{1}^{*}-\lambda_{1}w_{1}^{*}}=\innerprod{u}{0}=0.
    \end{equation}
    As $w_{1}^{*}>0$, if $Lu-\lambda_{1}u>0$, then $\innerprod{Lu-\lambda_{1}u}{w_{1}^{*}}>0$, contradict! So $\inf_{x\in U}(Lu-\lambda_{1}u)\le 0$.
\end{solution}
\begin{exercise}
(Eigenvalues and domain variations) Consider a family of smooth, bounded domains $U(\tau)\subset\mathbb{R}^{n}$ that depend smoothly upon the param
eter $\tau\in\mathbb{R}$. As $\tau$ changes, each points on $\partial U(\tau)$ moves with velocity $\mathbf{v}$.

For each $\tau$, we consider eigenvalues $\lambda=\lambda(\tau)$ and corresponding eigenfunctions $w=w(x,\tau)$:
\begin{equation}
    \label{eq:eig_prob_for_variable_domains}
    \left\{
    \begin{aligned}
        -\Delta w&=\lambda w, x\in U(\tau),\\
        w&=0,x\in\partial U(\tau),\\
    \end{aligned}
    \right.
\end{equation}
normalized so that $\norm{w}_{L^{2}(U(\tau))}=1$. Suppose that $\lambda$ and $w$ are smooth functions of $\tau$ and $x$, prove \textbf{Hadamard's variational formula}
\begin{equation}
    \label{eq:Hvf}
    \frac{\dif \lambda(\tau)}{\dif\tau}=-\int_{\partial U(\tau)}\left|\pdfFrac{w}{\nu}\right|^{2}\mathbf{v}\cdot\nu\dif S.
\end{equation}
\end{exercise}
\begin{solution}
    By \eqref{eq:eig_prob_for_variable_domains}, we can see:
    \begin{equation}
        \int_{U(\tau)}-w\Delta w\dif x=\int_{U(\tau)}\lambda(\tau)w^{2}\dif x.
    \end{equation}
    By the boundary conditions and Gauss-Green formula:
    \begin{equation}
        f(\tau)=\int_{U(\tau)}\left(|\nabla w|^{2}-\lambda(\tau)w^{2}\right)\dif x\equiv 0.
    \end{equation}
    For $\norm{w}_{L^{2}}=1$, it means that $\lambda(\tau)=\int_{U(\tau)}|\nabla w|^{2}\dif x$. Then, by \textbf{Reynold's transport theorem}:
    \begin{equation}
        \begin{aligned}
            \frac{\dif \lambda(\tau)}{\dif\tau}&=\int_{\partial U(\tau)}|\nabla w|^{2}\mathbf{v}\cdot\nu\dif S+\int_{U(\tau)}\pdfFrac{|\nabla w|^{2}}{\tau}\dif x\\
            &=\int_{\partial U(\tau)}\left|\pdfFrac{w}{\nu}\right|^{2}\mathbf{v}\cdot\nu\dif S+2\int_{U(\tau)}\nabla w\cdot\nabla w_{t}\dif x.
        \end{aligned}
    \end{equation}
    On the other hand:
    \begin{equation}
        \begin{aligned}
            &2\int_{U(\tau)}\nabla w\cdot\nabla w_{\tau}\dif x\\
            =&2\int_{U(\tau)}\nabla\cdot(w\nabla w_{\tau})\dif x-2\int_{U(\tau)}w\Delta w_{\tau}\dif x\\
            =&-2\int_{U(\tau)}w\pdfFrac{\Delta w}{\tau}\dif x\\
            =&2\int_{U(\tau)}w\pdfFrac{\lambda(\tau)w}{\tau}\dif x\\
            =&2\lambda'(\tau)\int_{U(\tau)}w^{2}\dif x+2\int_{U(\tau)}\lambda(\tau)w\pdfFrac{w}{\tau}\dif x\\
            =&2\lambda'(\tau)+2\int_{U(\tau)}\lambda w\pdfFrac{w}{\tau}\dif x=2\lambda'(\tau).
        \end{aligned}
    \end{equation}
    So:
    \begin{equation}
        \frac{\dif \lambda(\tau)}{\dif \tau}=-\int_{\partial U(\tau)}\lambda(\tau)w^{2}\dif x.
    \end{equation}
\end{solution}